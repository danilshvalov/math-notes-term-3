\documentclass[a5paper, 11pt]{extbook}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{tabularray}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{fontspec}
\usepackage[russian]{babel}
\usepackage{indentfirst}
\setmainfont{PT Astra Serif}
\usepackage[
    left=10mm,
    right=10mm,
    top=15mm,
    bottom=15mm
]{geometry}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{unicode-math}
\usepackage[math]{cellspace}
\usepackage{mathtools}

\pagestyle{plain}

\theoremstyle{definition}
\newtheorem{theorem}{Теорема}[section]
\renewcommand{\thetheorem}{\arabic{theorem}}

\newtheorem*{theorem*}{Теорема}

\newtheorem{lemma}{Лемма}[section]
\renewcommand{\thelemma}{\arabic{lemma}}

\newtheorem{property}{Свойство}[section]
\renewcommand{\theproperty}{\arabic{property}}

\theoremstyle{definition}
\newtheorem{definition}{Определение}[section]
\renewcommand{\thedefinition}{\arabic{definition}}

\theoremstyle{definition}
\newtheorem*{definition*}{Определение}

\newtheorem{consequence}{Следствие}[section]
\makeatletter
\counterwithin{consequence}{property}
\counterwithin{consequence}{theorem}
\makeatother
\renewcommand{\theconsequence}{\arabic{consequence}}

\newtheorem*{consequence*}{Следствие}

\newtheorem{note}{Замечание}[section]
\makeatletter
\counterwithin{note}{property}
\counterwithin{note}{theorem}
\makeatother
\renewcommand{\thenote}{\arabic{note}}

\newtheorem*{note*}{Замечание}


\newcommand{\newpar}{$ $\par\nobreak\ignorespaces}
\renewenvironment{proof}{{\noindent\bfseries Доказательство.}}{\smallskip\newpar \hfill\textit{Что и требовалось доказать.}}
\usepackage[x11names]{xcolor}
\hypersetup{linktoc = all, colorlinks = true, urlcolor = DodgerBlue4, citecolor = PaleGreen1, linkcolor = black}
\author{Daniil Shvalov}
\date{\today}
\title{}
\hypersetup{
    pdfauthor={Daniil Shvalov},
    pdftitle={},
    pdfkeywords={},
    pdfsubject={},
    pdflang={Russian}}


% Define math operators
\DeclareMathOperator{\rang}{rang}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\defect}{def}


% Draw line in matrix
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
    \hskip -\arraycolsep
    \let\@ifnextchar\new@ifnextchar
    \array{#1}}
\makeatother

% Add new table align types
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}}

\begin{document}

\tableofcontents

\setlist[itemize]{itemsep=0.5em,topsep=0em,parsep=0em}
\setlist[enumerate]{itemsep=0.5em,topsep=0em,parsep=0em}

\hypersetup{linktoc = all, colorlinks = true, urlcolor = DodgerBlue4, citecolor = PaleGreen1, linkcolor = blue}

\makeatletter
\def\thm@space@setup{\thm@preskip=1pt
    \thm@postskip=1pt}
\makeatother

\def\lets{%
    \mathord{\setbox0=\hbox{$\exists$}%
        \hbox{\kern 0.125\wd0%
            \vbox to \ht0{%
                \hrule width 0.75\wd0%
                \vfill%
                \hrule width 0.75\wd0}%
            \vrule height \ht0%
            \kern 0.125\wd0}%
    }%
}


\chapter{Матрицы и определители}
\label{sec:org37c4e21}
\section{Определения}
\label{sec:orgc3e0aac}
\begin{definition}
    Матрица размером \(m \times n\) — это таблица выражений, состоящая из \(m\) строк и \(n\) столбцов:

    \begin{equation*}
        \underset{m \times n}{A} =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        = (a_{ij}).
    \end{equation*}
\end{definition}

\begin{definition}
    След матрицы — это сумма диагональных элементов матрицы. Операция взятия следа обозначается \(\mathrm{tr}\):
    \begin{equation*}
        \underset{n \times n}{A} =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{n1} & a_{n2} & \ldots & a_{nn}
        \end{pmatrix};
        = (a_{ij})
        \qquad
        \mathrm{tr} A = \sum_{i = 1}^n = a_{11} + a_{22} + \ldots + a_{nn}
    \end{equation*}
\end{definition}

\begin{definition}
    Ранг матрицы — это наивысший порядок ненулевого минора. Ранг матрицы обозначается \(\rang\).
\end{definition}

\section{Виды матриц}
\label{sec:orgbc2a2b4}
В зависимости от размерности, матрицы имеют названия, приведенные в следующей таблице.
\begin{center}
    \begin{tabular}{|c|c|c|c|}
        Размерность    & Название      & Размерность    & Название        \\
        \hline
        \(m \times n\) & прямоугольная & \(1 \times n\) & матрица-строка  \\
        \(n \times n\) & квадратная    & \(m \times 1\) & матрица-столбец \\
    \end{tabular}
\end{center}

Элементы квадратной матрицы, имеющие одинаковые индексы (\(a_{11}\), \(a_{22}\), \(\ldots\), \(a_{nn}\)), образуют \emph{главную диагональ матрицы}. Диагональ, соединяющая элементы \(a_{1n}\), \(a_{2n}\), \(\ldots\), \(a_{n1}\), называется \emph{побочной диагональю матрицы}.

Квадратная матрица, у которой все элементы, расположенные выше (ниже) главной диагонали, равны нулю, называется \emph{нижней} (\emph{верхней}) \emph{треугольной матрицей}:
\begin{equation*}
    \text{нижняя:}
    \quad
    \begin{pmatrix}
        a_{11} & 0      & \ldots & 0      \\
        a_{21} & a_{22} & \ldots & 0      \\
        \ldots & \ldots & \ldots & \ldots \\
        a_{n1} & a_{n2} & \ldots & a_{nn}
    \end{pmatrix};
    \qquad \qquad
    \text{верхняя:}
    \quad
    \begin{pmatrix}
        a_{11} & a_{12} & \ldots & a_{1n} \\
        0      & a_{22} & \ldots & a_{2n} \\
        \ldots & \ldots & \ldots & \ldots \\
        0      & 0      & \ldots & a_{nn}
    \end{pmatrix}
\end{equation*}

Квадратная матрица, имеющая ненулевые элементы только на главной диагонали, называется \emph{диагональной}:
\begin{equation*}
    \mathrm{diag} \{ a_{11}, a_{22}, \ldots, a_{nn} \} =
    \begin{pmatrix}
        a_{11} & 0      & \ldots & 0      \\
        0      & a_{22} & \ldots & 0      \\
        \ldots & \ldots & \ldots & \ldots \\
        0      & 0      & \ldots & a_{nn}
    \end{pmatrix}
\end{equation*}

Диагональная матрица, у которой все элементы главной диагонали равны единицам, называется \emph{единичной}:
\begin{equation*}
    \underset{n \times n}{I} =
    \begin{pmatrix}
        1      & 0      & \ldots & 0      \\
        0      & 1      & \ldots & 0      \\
        \ldots & \ldots & \ldots & \ldots \\
        0      & 0      & \ldots & 1
    \end{pmatrix}
\end{equation*}

Прямоугольная матрица, все элементы которой равны нулю, называется \emph{нулевой}:
\begin{equation*}
    \underset{m \times n}{\Theta} =
    \begin{pmatrix}
        0      & 0      & \ldots & 0      \\
        0      & 0      & \ldots & 0      \\
        \ldots & \ldots & \ldots & \ldots \\
        0      & 0      & \ldots & 0
    \end{pmatrix}
\end{equation*}

Матрица \(A^T\), у которой по отношению к матрице \(A\) элементы строк и столбцов поменялись местами, называется \emph{транспонированной} по отношению к \(A\):
\begin{equation*}
    \underset{m \times n}{A} =
    \begin{pmatrix}
        a_{11} & a_{21} & \ldots & a_{m1} \\
        a_{12} & a_{22} & \ldots & a_{m2} \\
        \ldots & \ldots & \ldots & \ldots \\
        a_{1n} & a_{2n} & \ldots & a_{nm}
    \end{pmatrix}
    = \underset{m \times n}{A'}.
\end{equation*}

Матрица, для которой справедливо равенство \(A = A^T\) называется \emph{симметричной}.

\section{Краткая запись различных видов матриц}
\label{sec:org87e2b11}
Перечисленные выше основные виды матриц характеризуются определенными свойствами ее элементов. Введем \emph{символ Кронекера}:
\begin{equation*}
    \delta_{ij} =
    \begin{cases}
        1, \text{ если } i = j, \\
        0, \text{ если } i \neq j
    \end{cases}
\end{equation*}

В таблице ниже приведены условия, с помощью которых можно выразить ранее приведеные свойства для квадратных матриц \(A = (a_{ij}) \; (i,j = \overline{1,n})\).
\begin{center}
    \begin{tabular}{|c|c|c|c|}
        Условие                      & Название            & Условие                  & Название     \\
        \hline
        \(a_{ij} = 0\) при \(i > j\) & верхняя треугольная & \(a_{ij} = \delta_{ij}\) & единичная    \\
        \(a_{ij} = 0\) при \(i < j\) & нижняя треугольная  & \(a_{ij} = 0\)           & нулевая      \\
        \(a_{ij} = a_i \delta_{ij}\) & диагональная        & \(a_{ij} = a_{ji}\)      & симметричная \\
    \end{tabular}
\end{center}

\section{Линейные операции}
\label{sec:org268ca8b}
Рассмотрим операции, справедливые для матриц с размерностью \(m \times n\).

\subsection{Сравнение матриц}
\label{sec:org5bf4d2c}
Две матрицы одинаковых размеров называются равными, если совпадают их элементы с одинаковыми индексами:
\begin{equation*}
    A = B \iff a_{ij} = b_{ij}
\end{equation*}

\subsection{Сложение матриц}
\label{sec:org930f363}
Сложение матриц \(A + B\) есть операция нахождения матрицы \(C\), все элементы которой равны попарной сумме всех соответствующих элементов матриц \(A\) и \(B\):
\begin{equation*}
    C = A + B \iff c_{ij} = a_{ij} + b_{ij}
\end{equation*}

Свойства сложения матриц:
\begin{itemize}
    \item Коммутативность:
          \[
              A + B = B + A.
          \]
    \item Ассоциативность:
          \[
              A + B + C = (A + B) + C = A + (B + C).
          \]
    \item Сложение с нулевой матрицей:
          \[
              A + \theta = \theta + A = A.
          \]
    \item Существование противоположной матрицы:
          \[
              A + A^{-1} = 0.
          \]
\end{itemize}

\subsection{Умножение матрицы на число}
\label{sec:org006ca40}
Умножение матрицы \(A\) на число \(\lambda \in \mathcal{K}\) заключается в построении матрицы \(\lambda A = (\lambda a_{ij})\).

Свойства умножения матриц на число:
\begin{itemize}
    \item Ассоциативность:
          \[
              (\lambda \beta) A = \lambda (\beta A).
          \]
    \item Дистрибутивность:
          \[
              (\lambda + \beta) A = \lambda A + \beta A.
          \]
          \[
              \lambda (A + B) = \lambda A + \lambda B.
          \]
    \item Умножение на единицу:
          \[
              1 \cdot A = A \cdot 1 = A.
          \]
\end{itemize}

\subsection{Умножение матриц}
\label{sec:org3cd53f8}
Умножение матриц — операция вычисления матрицы \(C\), каждый элемент которой равен сумме произведений элементов в соответствующей строке первого множителя и столбце второго:

\begin{equation*}
    c_{ij} = \sum_{k=1}^n a_{ik} b_{kj}
\end{equation*}

Количество столбцов в матрице \(A\) должно совпадать с количеством строк в матрице \(B\). Если матрица \(A\) имеет размерность \(m \times n\), B — \(n \times k\), то размерность их произведения \(AB = C\) есть \(m \times k\).

Свойства умножения матриц:
\begin{itemize}
    \item Некоммутативность (в общем случае):
          \[
              AB \neq BA.
          \]
    \item Ассоциативность:
          \[
              (AB)C = A(BC).
          \]
    \item Коммутативность при умножении с единичной матрицей:
          \[
              AE = EA = A.
          \]
    \item Дистрибутивность:
          \[
              (A + B) C = AC + BC.
          \]
          \[
              A (B + C) = AB + BC.
          \]
    \item Ассоциативность и коммутативность умножения на число:
          \[
              (\lambda A) B = A (\lambda B) = \lambda (AB).
          \]
\end{itemize}

\section{Элементарные преобразования}
\label{sec:org11b71ac}
\begin{definition}
    Элементарные преобразования — это такие преобразования матрицы, в результате которых сохраняется эквивалентность матриц.
\end{definition}

Таким образом, элементарные преобразования не изменяют множество решений системы линейных алгебраических уравнений, которую представляет эта матрица. Элементарные операции обратимы. Обозначение \(A \sim B\) указывает на то, что матрица \(A\) может быть получена из матрицы \(B\) путем элементарных преобразований.

Примеры элементарных преобразований строк:
\begin{itemize}
    \item перестановка местами любых двух строк матрицы;
    \item умножение любой строки матрицы на константу \(k \neq 0\), при этом определитель матрицы увеличивается в \(k\) раз;
    \item прибавление к любой строке матрицы другой строки, умноженной на некоторую константу;
    \item удаление нулевых строк;
    \item транспонирование.
\end{itemize}

Аналогично определяются элементарные преобразования столбцов.

\section{Свойства транспонирования матриц}
\label{sec:orgb619c51}

\begin{property}
    \begin{equation*}
        (A^T)^T = A
    \end{equation*}
\end{property}

\begin{proof}
    \begin{gather*}
        A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        \implies
        A^T =
        \begin{pmatrix}
            a_{11} & a_{21} & \ldots & a_{m1} \\
            a_{12} & a_{22} & \ldots & a_{m2} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{1n} & a_{2n} & \ldots & a_{mn}
        \end{pmatrix}
        \implies \\
        \implies
        (A^T)^T =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        = A
    \end{gather*}
\end{proof}


\begin{property}
    \begin{equation*}
        (A + B)^T = A^T + B^T
    \end{equation*}
\end{property}

\begin{proof}
    \begin{equation*}
        A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        \qquad
        B =
        \begin{pmatrix}
            b_{11} & b_{12} & \ldots & b_{1n} \\
            b_{21} & b_{22} & \ldots & b_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            b_{m1} & b_{m2} & \ldots & b_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        A^T =
        \begin{pmatrix}
            a_{11} & a_{21} & \ldots & a_{m1} \\
            a_{11} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{1n} & a_{2n} & \ldots & a_{mn}
        \end{pmatrix}
        \qquad
        B^T =
        \begin{pmatrix}
            b_{11} & b_{21} & \ldots & b_{m1} \\
            b_{11} & b_{22} & \ldots & b_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            b_{1n} & b_{2n} & \ldots & b_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        A + B =
        \begin{pmatrix}
            a_{11} + b_{11} & a_{12} + b_{12} & \ldots & a_{1n} + b_{1n} \\
            a_{21} + b_{21} & a_{22} + b_{22} & \ldots & a_{2n} + b_{2n} \\
            \ldots          & \ldots          & \ldots & \ldots          \\
            a_{m1} + b_{m1} & a_{m2} + b_{m2} & \ldots & a_{mn} + b_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        (A + B)^T =
        \begin{pmatrix}
            a_{11} + b_{11} & a_{21} + b_{21} & \ldots & a_{m1} + b_{m1} \\
            a_{12} + b_{12} & a_{22} + b_{22} & \ldots & a_{m2} + b_{m2} \\
            \ldots          & \ldots          & \ldots & \ldots          \\
            a_{1n} + b_{1n} & a_{2n} + b_{2n} & \ldots & a_{mn} + b_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        A^T + B^T =
        \begin{pmatrix}
            a_{11} + b_{11} & a_{21} + b_{21} & \ldots & a_{m1} + b_{m1} \\
            a_{12} + b_{12} & a_{22} + b_{22} & \ldots & a_{m2} + b_{m2} \\
            \ldots          & \ldots          & \ldots & \ldots          \\
            a_{1n} + b_{1n} & a_{2n} + b_{2n} & \ldots & a_{mn} + b_{mn}
        \end{pmatrix}
    \end{equation*}
\end{proof}

\begin{property}
    \begin{equation*}
        (\lambda A)^T = \lambda A^T
    \end{equation*}
\end{property}

\begin{proof}
    \begin{equation*}
        A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        \lambda A =
        \begin{pmatrix}
            \lambda a_{11} & \lambda a_{12} & \ldots & \lambda a_{1n} \\
            \lambda a_{21} & \lambda a_{22} & \ldots & \lambda a_{2n} \\
            \ldots         & \ldots         & \ldots & \ldots         \\
            \lambda a_{m1} & \lambda a_{m2} & \ldots & \lambda a_{mn}
        \end{pmatrix}
        \qquad
        (\lambda A)^T =
        \begin{pmatrix}
            \lambda a_{11} & \lambda a_{21} & \ldots & \lambda a_{m1} \\
            \lambda a_{12} & \lambda a_{22} & \ldots & \lambda a_{m2} \\
            \ldots         & \ldots         & \ldots & \ldots         \\
            \lambda a_{1n} & \lambda a_{m2} & \ldots & \lambda a_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        A^T =
        \begin{pmatrix}
            a_{11} & a_{21} & \ldots & a_{m1} \\
            a_{12} & a_{22} & \ldots & a_{m2} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{1n} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        \qquad
        \lambda A^T =
        \begin{pmatrix}
            \lambda a_{11} & \lambda a_{21} & \ldots & \lambda a_{m1} \\
            \lambda a_{12} & \lambda a_{22} & \ldots & \lambda a_{m2} \\
            \ldots         & \ldots         & \ldots & \ldots         \\
            \lambda a_{1n} & \lambda a_{m2} & \ldots & \lambda a_{mn}
        \end{pmatrix}
    \end{equation*}
\end{proof}

\begin{property}
    \begin{equation*}
        (A \cdot B)^T = B^T \cdot A^T
    \end{equation*}
    \label{tr-matrix-mul}
\end{property}

\begin{proof}
    \begin{equation*}
        A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn}
        \end{pmatrix}
        \qquad
        B =
        \begin{pmatrix}
            b_{11} & b_{12} & \ldots & b_{1n} \\
            b_{21} & b_{22} & \ldots & b_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            b_{m1} & b_{m2} & \ldots & b_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        A^T = C =
        \begin{pmatrix}
            c_{11} & c_{21} & \ldots & c_{m1} \\
            c_{11} & c_{22} & \ldots & c_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            c_{1n} & c_{2n} & \ldots & c_{mn}
        \end{pmatrix}
        \qquad
        B^T = D =
        \begin{pmatrix}
            d_{11} & d_{21} & \ldots & d_{m1} \\
            d_{11} & d_{22} & \ldots & d_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            d_{1n} & d_{2n} & \ldots & d_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        \begin{cases}
            a_{ij} = c_{ji} \\
            b_{\alpha \beta} = d_{\beta \alpha}
        \end{cases}
    \end{equation*}

    \begin{equation*}
        A \cdot B = F =
        \begin{pmatrix}
            f_{11} & f_{21} & \ldots & f_{m1} \\
            f_{11} & f_{22} & \ldots & f_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            f_{1n} & f_{2n} & \ldots & f_{mn}
        \end{pmatrix}
        \qquad
        B^T \cdot A^T = G =
        \begin{pmatrix}
            g_{11} & g_{21} & \ldots & g_{m1} \\
            g_{11} & g_{22} & \ldots & g_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            g_{1n} & g_{2n} & \ldots & g_{mn}
        \end{pmatrix}
    \end{equation*}

    \begin{equation*}
        g_{ji} =
        \sum_{\alpha = 1}^k d_{j \alpha} c_{\alpha i} =
        \sum_{\alpha = 1}^k b_{\alpha j} a_{i \alpha} =
        \sum_{\alpha = 1}^k a_{i \alpha} b_{\alpha j} =
        f_{ij}
    \end{equation*}

    \begin{equation*}
        G = F^T \implies (A \cdot B)^T = B^T \cdot A^T
    \end{equation*}
\end{proof}

\section{Вычисление определителей}
\label{sec:org6c787bc}
\begin{theorem}[о раздложении определителя]
    Определителем порядка \(n\), соответствующим квадратной матрице порядка \(n\), называется число, равное
    \[
        \det A = \sum_{i = 1}^n a_{ij} A_{ij} = \sum_{j = 1}^n a_{ij} A_{ij} = \sum_{i = 1}^n (-1)^{i + j} a_{ij} M_{ij}.
    \]
    где
    \begin{itemize}
        \item \(i, j \in (\overline{1,n})\);
        \item \(A_{ij}\) — соответствующее алгебраическое дополнение \(a_{ij}\);
        \item \(M_{ij}\) — соответствующий минор элемента \(a_{ij}\).
    \end{itemize}
    \label{det-decomposition}
\end{theorem}

\begin{proof}
    Опираясь на основные свойства определителей, выпишем цепочку равенств:
    \begin{gather*}
        \det A =
        \begin{vmatrix}
            a_{11} & \ldots & a_{1j} & \ldots & a_{1n} \\
            a_{21} & \ldots & a_{2j} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots          \\
            a_{n1} & \ldots & a_{nj} & \ldots & a_{nn} \\
        \end{vmatrix}
        = \\ =
        \begin{vmatrix}
            a_{11} & \ldots & a_{1j} & \ldots & a_{1n} \\
            a_{21} & \ldots & 0      & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots          \\
            a_{n1} & \ldots & 0      & \ldots & a_{nn} \\
        \end{vmatrix}
        +
        \begin{vmatrix}
            a_{11} & \ldots & 0      & \ldots & a_{1n} \\
            a_{21} & \ldots & a_{2j} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots          \\
            a_{n1} & \ldots & 0      & \ldots & a_{nn} \\
        \end{vmatrix}
        + \ldots + \\ +
        \begin{vmatrix}
            a_{11} & \ldots & 0      & \ldots & a_{1n} \\
            a_{21} & \ldots & 0      & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots          \\
            a_{n1} & \ldots & a_{nj} & \ldots & a_{nn} \\
        \end{vmatrix}
        =
        \sum_{i = 1}^n
        \begin{vmatrix}
            a_{11} & \ldots & a_{1j - 1} & 0      & a_{1j + 1} & \ldots & a_{1n} \\
            \ldots & \ldots & \ldots     & \ldots & \ldots     & \ldots          \\
            a_{i1} & \ldots & a_{ij - 1} & a_{ij} & a_{ij + 1} & \ldots & a_{in} \\
            \ldots & \ldots & \ldots     & \ldots & \ldots     & \ldots          \\
            a_{n1} & \ldots & a_{nj - 1} & 0      & a_{nj + 1} & \ldots & a_{nn} \\
        \end{vmatrix}
        = \\ =
        \sum_{i = 1}^n
        \begin{vmatrix}
            a_{ij} & a_{i1}      & \ldots & a_{ij - 1}      & a_{ij + 1}      & \ldots & a_{in}        \\
            0      & a_{11}      & \ldots & a_{1j - 1}      & a_{1j + 1}      & \ldots & a_{1n}        \\
            \ldots & \ldots      & \ldots & \ldots          & \ldots          & \ldots & \ldots      & \\
            0      & a_{i - 1,1} & \ldots & a_{i - 1,j - 1} & a_{i - 1,j + 1} & \ldots & a_{i - 1,n}   \\
            0      & a_{i + 1,1} & \ldots & a_{i + 1,j - 1} & a_{i + 1,j + 1} & \ldots & a_{i + 1,n}   \\
            \ldots & \ldots      & \ldots & \ldots          & \ldots          & \ldots & \ldots      & \\
            0      & a_{n1}      & \ldots & a_{nj - 1}      & a_{nj + 1}      & \ldots & a_{nn}
        \end{vmatrix}
        =
        \sum_{i = 1}^n (-1)^{i + j} a_{ij} M_{ij}.
    \end{gather*}
    Таким образом, часть теоремы доказана. Положим теперь \(A^T = (a'_{ij})\), где \(a'_{ji} = a_{ij}\). Заметим, что соответствующим элементу \(a'_{ji}\) в \(\det A^T\) будет \(M'_{ji} = M_{ij}\). Как было показано выше,
    \[
        \det A = \det A^T = \sum_{j = 1}^n (-1)^{j + i} a'_{ji} M'_{ji} = \sum_{j = 1}^n (-1)^{i + j} a_{ij} M_{ij}.
    \]
\end{proof}

\section{Присоединенная матрица}
\label{sec:org9f4f382}
\begin{definition}
    Присоединенная матрица \(A^c\) — это транспонированная матрица алгебраических дополнений \(A_{ij}\) элементов \(a_{ij}\) матрицы \(A\):
    \begin{equation*}
        A^c =
        \begin{pmatrix}
            A_{11} & A_{21} & \ldots & A_{n1} \\
            A_{12} & A_{22} & \ldots & A_{n2} \\
            \ldots & \ldots & \ldots & \ldots \\
            A_{1n} & A_{2n} & \ldots & A_{nn}
        \end{pmatrix};
    \end{equation*}
\end{definition}

\begin{theorem}[Аннулирование]
    Сумма произведений  элементов любой строки (или столбца) на алгебраические дополнения элементов другой строки (столбца) равна нулю:
    \begin{equation*}
        \sum_{k = 1}^n a_{ik} A_{jk} = 0, \quad (i \neq j);
        \qquad
        \sum_{k = 1}^n a_{ki} A_{kj} = 0, \quad (i \neq j).
    \end{equation*}
    \label{det-cancellation}
\end{theorem}

\begin{proof}
    Рассмотрим вспомогательную матрицу \(A'\), полученную из матрицы \(A\), заменой \(j\)-ой строки \(i\)-ой строкой:
    \begin{equation*}
        A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{i1} & a_{i2} & \ldots & a_{in} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{j1} & a_{j2} & \ldots & a_{jn} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{n1} & a_{n2} & \ldots & a_{nn}
        \end{pmatrix};
        \qquad
        A' =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{i1} & a_{i2} & \ldots & a_{in} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{j1} & a_{j2} & \ldots & a_{jn} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{n1} & a_{n2} & \ldots & a_{nn}
        \end{pmatrix}.
    \end{equation*}
    \begin{equation*}
        \det A' = \sum_{k = 1}^n a_{jk} A'_{jk} = \sum_{k = 1}^n a_{ik} A'_{jk}.
    \end{equation*}
    Заметим, что алгебраическое дополнение элемента некоторой строки не зависит от элементов этой строки (поскольку при вычислении алгебраического дополнения эта строка просто вычеркивается). Однако матрицы \(A\) и \(A'\) отличаются только \(j\)-ой строкой, следовательно, \(A_{jk} = A'_{jk}\). Тогда
    \begin{equation*}
        \det A' = \sum_{k = 1}^n a_{ik} A_{jk}.
    \end{equation*}
    Поскольку матрица \(A'\) имеет две одинаковые строки, ее определитель равен нулю. Аналогично доказывается случай со столбцами.
\end{proof}

\section{Невырожденная матрица}
\label{sec:org110d88a}
\begin{definition}
    Невырожденная матрица — это квадратная матрица, определитель которой отличен от нуля. В противном случае матрица называется вырожденной.
\end{definition}

\section{Обратная матрица}
\label{sec:org866276c}

\begin{definition}
    Обратная матрица — это такая матрица \(A^{-1}\), при умножении которой на исходную матрицу \(A\) получается единичная матрица \(E\):

    \begin{equation*}
        AA^{-1} = A^{-1}A = E.
    \end{equation*}
\end{definition}

\subsection{Свойства обратной матрицы}
\label{sec:org7ec2f44}

\begin{property}
    \begin{equation*}
        \det A^{-1} = (\det A)^{-1}
    \end{equation*}
\end{property}

\begin{proof}
    \begin{gather*}
        \det E = \det (A^{-1} A) = \det A^{-1} \det A \\
        \det A^{-1} = \frac{\det E}{\det A} = \frac{1}{\det A} = (\det A)^{-1}
    \end{gather*}
\end{proof}

\begin{property}
    \begin{equation*}
        (AB)^{-1} = B^{-1}A^{-1}
    \end{equation*}
\end{property}

\begin{proof}
    \begin{gather*}
        \begin{cases}
            B^{-1} A^{-1} AB = B^{-1} E B = E \\
            AB B^{-1} A^{-1} = A E A^{-1} = E
        \end{cases}
        \implies
        (AB)^{-1} = B^{-1} A^{-1}.
    \end{gather*}
\end{proof}

\begin{property}
    \begin{equation*}
        (A^T)^{-1} = (A^{-1})^T
    \end{equation*}
\end{property}

\begin{proof}
    Воспользуемся \hyperref[tr-matrix-mul]{одним из свойств} транспонированных матриц
    \begin{equation*}
        \begin{cases}
            (A^{-1})^T A^T = (A^{-1} A)^T = E^T = E \\
            A^T (A^{-1})^T = (A A^{-1})^T = E^T = E
        \end{cases}
        \implies
        (A^{-1})^T = A^T.
    \end{equation*}
\end{proof}

\begin{property}
    \begin{equation*}
        (A^{-1})^{-1} = A
    \end{equation*}
\end{property}

\begin{proof}
    \begin{gather*}
        (A^{-1})^{-1} = A
        \quad
        \implies
        \quad
        (A^{-1})^{-1} A^{-1} A = A
        \quad
        \stackrel{2 \; \text{св.}}{\implies}
        \quad
        (A A^{-1})^{-1} A = A
        \quad
        \implies \\
        \implies
        \quad
        (A A^{-1})^{-1} A = A
        \quad
        \implies
        \quad
        E^{-1} A = A
        \quad
        \implies
        \quad
        A = A
    \end{gather*}
\end{proof}

\begin{property}
    \begin{equation*}
        (\lambda A)^{-1} = \lambda^{-1} A^{-1}
    \end{equation*}
\end{property}

\begin{proof}
    \begin{equation*}
        \begin{cases}
            \lambda A \lambda^{-1} A^{-1} = 1E = E \\
            \lambda^{-1} A^{-1} \lambda A = 1E = E
        \end{cases}
        \implies
        (\lambda A)^{-1} = \lambda^{-1} A^{-1}.
    \end{equation*}
\end{proof}

\subsection{Теоремы}
\label{sec:org46113a8}

\begin{theorem}
    Для всякой невырожденной матрицы \(A\) существует обратная матрица \(A^{-1}\) и притом только одна.
\end{theorem}

\begin{proof}
    Сначала докажем существование обратной матрицы. Пусть нам дана следующая матрица \(A\), определитель которой не равен нулю:
    \begin{equation*}
        A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{i1} & a_{i2} & \ldots & a_{in} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{n1} & a_{n2} & \ldots & a_{nn}
        \end{pmatrix}
    \end{equation*}

    Для этой матрицы построим \hyperref[sec:org9f4f382]{присоединенную матрицу}:
    \begin{equation*}
        A^c =
        \begin{pmatrix}
            A_{11} & A_{21} & \ldots & A_{n1} \\
            A_{12} & A_{22} & \ldots & A_{n2} \\
            \ldots & \ldots & \ldots & \ldots \\
            A_{1n} & A_{2n} & \ldots & A_{nn}
        \end{pmatrix}
    \end{equation*}

    Перемножим матрицы \(A\) и \(A^c\):
    \begin{gather*}
        A^c A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{i1} & a_{i2} & \ldots & a_{in} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{n1} & a_{n2} & \ldots & a_{nn}
        \end{pmatrix}
        \begin{pmatrix}
            A_{11} & A_{21} & \ldots & A_{n1} \\
            A_{12} & A_{22} & \ldots & A_{n2} \\
            \ldots & \ldots & \ldots & \ldots \\
            A_{1n} & A_{2n} & \ldots & A_{nn}
        \end{pmatrix}
        = \\ =
        \setlength{\cellspacetoplimit}{3pt}
        \setlength{\cellspacebottomlimit}{3pt}
        \begin{pmatrix}
            \sum_{k = 1}^n A_{k1} a_{k1} & \sum_{k = 1}^n A_{k1} a_{k2} & \ldots & \sum_{k = 1}^n A_{k1} a_{kn} \\
            \sum_{k = 1}^n A_{k2} a_{k1} & \sum_{k = 1}^n A_{k2} a_{k2} & \ldots & \sum_{k = 1}^n A_{k2} a_{kn} \\
            \ldots                       & \ldots                       & \ldots & \ldots                       \\
            \sum_{k = 1}^n A_{kn} a_{k1} & \sum_{k = 1}^n A_{kn} a_{k2} & \ldots & \sum_{k = 1}^n A_{kn} a_{kn} \\
        \end{pmatrix}
    \end{gather*}

    По \hyperref[det-decomposition]{теореме о разложении определителя} и \hyperref[det-cancellation]{теореме аннулирования}:
    \begin{equation*}
        \begin{cases}
            i = k \implies \sum_{k = 1}^n a_{ik} A_{jk} = \det A \\
            i \neq k \implies \sum_{k = 1}^n a_{ik} A_{jk} = 0
        \end{cases}
    \end{equation*}

    Тогда получим, что
    \begin{equation*}
        A^c A =
        \begin{pmatrix}
            \det A & 0      & \ldots & 0      \\
            0      & \det A & \ldots & 0      \\
            \ldots & \ldots & \ldots & \ldots \\
            0      & 0      & \ldots & \det A \\
        \end{pmatrix}
        = \det A
        \begin{pmatrix}
            1      & 0      & \ldots & 0      \\
            0      & 1      & \ldots & 0      \\
            \ldots & \ldots & \ldots & \ldots \\
            0      & 0      & \ldots & 1      \\
        \end{pmatrix}
        = E \det A.
    \end{equation*}

    Значит обратная матрица равна
    \begin{equation*}
        A^{-1} = \frac{A^c}{\det A}.
    \end{equation*}

    Аналогично доказывается случай \(A A^c\), Теперь докажем единственность обратной матрицы. Предположим, что существует две обратные матрицы: \(A^{-1}\) и \(\tilde{A}\). Тогда
    \begin{gather*}
        \begin{cases}
            AA^{-1} = A^{-1} A = E \\
            A\tilde{A} = \tilde{A} A = E
        \end{cases}
        \implies
        A^{-1} A \tilde{A} =
        \begin{cases}
            A^{-1} (A\tilde{A}) = A^{-1} E = A^{-1} \\
            (A^{-1} A) \tilde{A} = E \tilde{A} = \tilde{A}
        \end{cases}
        \implies \\ \implies
        A^{-1} = \tilde{A}.
    \end{gather*}

    Результат противоречит исходному предположению о существовании двух обратных матриц.
\end{proof}

\section{Норма матрицы}
\label{sec:org5cea476}
\begin{definition}
    Нормой матрицы \(A \in \mathcal{K}^{m \times n}\) (обычно \(\mathcal{K} = \mathbb{R}\) или \(\mathcal{K} = \mathbb{C}\)) понимается неотрицательное число \(\|A\|\), удовлетворяющее следующим аксиомам:
    \begin{enumerate}
        \item \(\|A\| \geq 0\);
        \item \(\|\lambda A\| = |\lambda| \|A\|\), где \(\lambda \in \mathbb{R}\) или \(\lambda \in \mathbb{C}\);
        \item \(\|A + B\| \leq \|A\| + \|B\|\), где \(A\) и \(B\) — матрицы, допускающие сложение;
        \item \(\|AB\| \leq \|A\| \|B\|\), где \(A\) и \(B\) — матрицы, допускающие умножение.
    \end{enumerate}
\end{definition}

\begin{definition}
    Норма \(\|A\|\) называется \emph{мультипликативной}, если выполняются все 4 аксиомы, и \emph{аддитивной}, если выполняются первые 3 аксиомы.
\end{definition}

\begin{definition}
    Если матрица удовлетворяет условию
    \[
        \|\lambda A\| \leq |\lambda| \|A\|,
    \]
    то такая норма называются \emph{согласованной} с нормой вектора.
\end{definition}

Определим некоторые наиболее употребительные на практике матричные нормы:
\begin{itemize}
    \item Евклидова норма или норма Фробениуса:
          \[
              \|A\|_E = \sqrt{\sum_{i = 1}^m \sum_{j = 1}^n a_{ij}^2}.
          \]
    \item Столбцовая норма:
          \[
              \|A\|_1 = \max_{1 \leq j \leq n} \sum_{i = 1}^m |a_{ij}|.
          \]
    \item Строковая форма:
          \[
              \|A\|_\infty = \max_{1 \leq i \leq m} \sum_{j = 1}^n |a_{ij}|.
          \]
    \item Спектральная норма:
          \[
              \|A\|_2 = \sqrt{\max_i(\sigma_i)},
          \]
          где \(\sigma_i\) — собственные значения симметричной матрицы \(A^T A\).
\end{itemize}

\section{Базисный минор}

\begin{definition}
    Если \(\rang A = r\), то любой ненулевой минор порядка \(r\) называется \textit{базисным минором}, а его строки (столбцы) — \textit{базисными}.
\end{definition}

\begin{theorem}[о базисном миноре]
    Базисные строки (столбцы) матрицы \(A\), соответствующие любому ее базисному минору \(M\), \textit{линейно независимы}. Любые строки (столбцы) матрицы \(A\), не входящие в \(M\), являются линейными комбинациями базисных строк (столбцов).
\end{theorem}

% TODO: Добавить доказательство

\section{Система линейных алгебраических уравнений}

\begin{definition}
    Система линейных алгебраических уравнений (СЛАУ, СЛУ) — система уравнений, каждое уравнение в которой является \textit{линейным} — алгебраическим уравнением первой степени.
\end{definition}

\begin{definition}
    \label{def:augmented-matrix}
    Расширенная матрица — матрица, которая получается при добавлении в качестве (n+1) столбца матрицу-столбец свободных членов. Приведем пример. Пусть дана матрица коэффициентов \(A\) и матрица свободных членов \(B\):
    \begin{equation*}
        A =
        \begin{pmatrix}
            a_{11} & a_{12} & \ldots & a_{1n} \\
            a_{21} & a_{22} & \ldots & a_{2n} \\
            \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn} \\
        \end{pmatrix};
        \qquad \qquad
        B =
        \begin{pmatrix}
            b_1    \\
            b_2    \\
            \ldots \\
            b_m    \\
        \end{pmatrix}.
    \end{equation*}
    Тогда расширенная матрица \(P\) будет иметь вид:
    \begin{equation*}
        P =
        \begin{pmatrix}[cccc|c]
            a_{11} & a_{12} & \ldots & a_{1n} & b_1    \\
            a_{21} & a_{22} & \ldots & a_{2n} & b_2    \\
            \ldots & \ldots & \ldots & \ldots & \ldots \\
            a_{m1} & a_{m2} & \ldots & a_{mn} & b_m    \\
        \end{pmatrix}.
    \end{equation*}
\end{definition}

СЛАУ можно записать в матричном виде:
\begin{equation*}
    \underset{m \times n}{A} =
    \begin{pmatrix}
        a_{11} & a_{12} & \ldots & a_{1n} \\
        a_{21} & a_{22} & \ldots & a_{2n} \\
        \ldots & \ldots & \ldots & \ldots \\
        a_{m1} & a_{m2} & \ldots & a_{mn} \\
    \end{pmatrix};
    \qquad
    \underset{n \times 1}{X} =
    \begin{pmatrix}
        x_1    \\
        x_2    \\
        \ldots \\
        x_n
    \end{pmatrix};
    \qquad
    \underset{m \times 1}{B} =
    \begin{pmatrix}
        b_1    \\
        b_2    \\
        \ldots \\
        b_m
    \end{pmatrix}.
\end{equation*}

\begin{equation*}
    AX = B
    \implies
    A^{1} A X = A^{-1} B
    \implies
    X = A^{-1} B.
\end{equation*}

% TODO: доказательство следствий
\begin{theorem}[Кронекера–Капелли]
    Система линейных алгебраических уравнений будет совместной тогда и только тогда, когда ранг матрицы \(A\) ее коэффициентов и ранг расширенной матрицы \(P\) равны. Из этого утверждения следует, что для СЛАУ справедливо следующее:
    \begin{itemize}
        \item \(\rang A = \rang P = n\) — имеет единственное решение;
        \item \(\rang A = \rang P < n\) — имеет бесконечное множество решений;
        \item \(\rang A < \rang P\) — не имеет решений.
    \end{itemize}
\end{theorem}

\begin{proof}
    \newpar
    \textbf{Необходимость}. Пусть система совместна, тогда найдутся такие числа
    \[
        \alpha_1, \alpha_2, \ldots, \alpha_n,
    \]
    что при подстановке которых в систему мы получим \(m\) тождеств, которые можно записать в виде одного векторного тождества:
    \begin{equation*}
        \alpha_1
        \begin{pmatrix}
            a_{11} \\
            a_{21} \\
            \ldots \\
            a_{m1}
        \end{pmatrix}
        +
        \alpha_2
        \begin{pmatrix}
            a_{12} \\
            a_{22} \\
            \ldots \\
            a_{m2}
        \end{pmatrix}
        + \ldots +
        \alpha_n
        \begin{pmatrix}
            a_{1n} \\
            a_{2n} \\
            \ldots \\
            a_{mn}
        \end{pmatrix}
        =
        \begin{pmatrix}
            b_1    \\
            b_2    \\
            \ldots \\
            b_m
        \end{pmatrix}
    \end{equation*}
    Следовательно, вектор-столбец свободных членов \(B\) является линейной комбинацией вектор-столбцов матрицы \(A\), тогда добавление его к системе векторов-столбцов матрицы \(A\) не меняет ранга системы. Отсюда \(\rang A = \rang R\).

    \textbf{Достаточность}. Пусть \(\rang A = \rang P = r\), следовательно существует линейно независимая подсистема из \(r\) векторов-столбцов матрицы \(A\). Она же будет содержаться и в матрице \(P\). Так как эта система максимальна, то вектор-столбец свободных членов \(B\) будет выражаться через эти \(r\) векторов-столбцов. Следовательно, вектор-столбец свободных членов \(B\) можно представить в виде линейной комбинации всех векторов-столбцов матрицы \(A\), т. е. найдутся такие числа \(\alpha_1, \alpha_2, \ldots, \alpha_n\), что вектор-столбец будет представлен в виде:
    \begin{equation*}
        \begin{pmatrix}
            b_1    \\
            b_2    \\
            \ldots \\
            b_m
        \end{pmatrix}
        =
        \alpha_1
        \begin{pmatrix}
            a_{11} \\
            a_{21} \\
            \ldots \\
            a_{m1}
        \end{pmatrix}
        +
        \alpha_2
        \begin{pmatrix}
            a_{12} \\
            a_{22} \\
            \ldots \\
            a_{m2}
        \end{pmatrix}
        + \ldots +
        \alpha_n
        \begin{pmatrix}
            a_{1n} \\
            a_{2n} \\
            \ldots \\
            a_{mn}
        \end{pmatrix}
    \end{equation*}
\end{proof}


\section{Однородные системы линейных алгебраических уравнений}

\begin{definition}
    Однородная система уравнений (ОСЛУ) — это система линейных уравнений, у которой все свободные члены равны нулю:
    \begin{equation*}
        \begin{cases}
            a_{11} x_1 + a_{12} x_2 + \ldots + a_{1n} x_n = 0 \\
            a_{21} x_1 + a_{22} x_2 + \ldots + a_{2n} x_n = 0 \\
            \dotfill                                          \\
            a_{m1} x_1 + a_{m2} x_2 + \ldots + a_{mn} x_n = 0
        \end{cases}
    \end{equation*}
\end{definition}

Любая ОСЛУ всегда совместна, поскольку всегда обладает нулевым (тривиальным) решением:
\begin{equation*}
    x_1 = x_2 = \ldots = x_n = 0.
\end{equation*}

\begin{theorem}
    Если \(\rang A = n\) и \(\det A \neq 0\), тогда система имеет единственное решение.
\end{theorem}

\begin{theorem}
    Если \(\rang A < n\) и \(\det A = 0\), тогда система имеет множество решений.
\end{theorem}

\begin{theorem}
    Если \(X\) и \(Y\) — решения ОСЛУ, то любая линейная комбинация \(\alpha X + \beta Y\) тоже является решением ОСЛУ.
\end{theorem}

\section{Фундаментальная система решений}

\begin{definition}
    Фундаментальная система решений (ФСР) — это совокупность ненулевых решений ОСЛУ \(x_1; x_2; \ldots; x_k\), если
    \begin{enumerate}
        \item \(x_1; x_2; \ldots; x_k\) линейно независимы;
        \item любое другое ненулевое решение \(x\) ОСЛУ может быть представлено линейной комбинацией \(x_1; x_2; \ldots; x_k\), то есть общее решение ОСЛУ
              \begin{equation*}
                  x = \alpha_1 x_1 + \alpha_2 x_2 + \ldots + \alpha_k x_k,
                  \quad
                  \alpha_i \in R.
              \end{equation*}
    \end{enumerate}
\end{definition}

\chapter{Векторное пространство}

\section{Определение}

\begin{definition}
    Векторным (линейным) пространством называется множество \(L\) произвольных элементов, называемых векторами, если для них:
    \begin{itemize}
        \item определена операция \textbf{сложения} векторов \(L \times L \to L\), сопоставляющая каждой паре элементов \((x, y) \in L\) единственный элемент множества \(L\), называемый их суммой и обозначаемый \(x + y\);
        \item определена операция \textbf{умножения} векторов на скаляры \(F \times L \to L\) (\(F\) — множество скаляров), сопоставляющая каждому элементу \(\lambda \in F\) и каждому элементу \(x \in L\) единственный элемент множества \(L\), обозначаемый \(\lambda \cdot x\) или \(\lambda x\).
    \end{itemize}

    Эти операции должны удовлетворять \hyperref[sec:vector-space-axiom]{восьми аксиомам векторного пространства}.
\end{definition}

\noindent Примеры линейных пространств:
\begin{itemize}
    \item множество \(\mathbb{R}\)
    \item множество всех матриц
    \item множество всех многочленов \(P_n (x) = a_0 x^n + a_1 x^{n - 1} + \ldots + a_n\), \(a_i \in \mathbb{R}\), \(i = \overline{1, n}\)
    \item \(n\)-мерное пространство арифметических векторов \(A_n\) \(n = 1, 2, \ldots\)
    \item множество всех функций, интегрируемых на \([a, b]\)
\end{itemize}

\section{Аксиомы векторного пространства}
\label{sec:vector-space-axiom}

\subsection{Аксиомы сложения}

\begin{enumerate}
    \item Коммутативность:
          \[
              \forall x, y \in L \implies x + y = y + x.
          \]
    \item Ассоциативность:
          \[
              \forall x, y, z \in L \implies x + (y + z) = (x + y) + z.
          \]
    \item Существование нейтрального элемента:
          \[
              \exists 0 \in L: x + 0 = 0 + x = x.
          \]
    \item Существование противоположного элемента:
          \[
              \forall x \in L \; \exists (-x) \in L: x + (-x) = 0.
          \]
\end{enumerate}

\subsection{Аксиомы умножения}

\begin{enumerate}
    \item Ассоциативность:
          \[
              \alpha (\beta x) = (\alpha \beta)x.
          \]
    \item Дистрибутивность относительно сложения скаляров:
          \[
              (\alpha + \beta)x = \alpha x + \beta x.
          \]
    \item Дистрибутивность относительно сложения векторов:
          \[
              \alpha (x + y) = \alpha x + \alpha y.
          \]
    \item Существование нейтрального элемента:
          \[
              1 \cdot x  = x.
          \]
\end{enumerate}

\section{Линейная зависимость и независимость векторов}

\begin{definition}
    Система из \(k\) векторов \(\vec{a}_1, \vec{a}_2, \ldots, \vec{a}_k\) называется \textbf{линейно зависимой}, если существуют такие числа \(\alpha_1, \alpha_2, \ldots, \alpha_k\), не равные нулю одновременно, что
    \begin{equation*}
        \alpha_1 \vec{a}_1 + \alpha_2 \vec{a}_2 + \ldots + \alpha_k \vec{a}_k = 0.
    \end{equation*}
    Если это равенство справедливо только при \(\alpha_1 = \alpha_2 = \ldots = \alpha_k\), тогда эта система называется \textbf{линейно независимой}.
\end{definition}

% Пусть \(Q \sub L\) — произвольное множество векторов, тогда упорядоченная система векторов \(E = (e_1, e_2, \ldots, e_s)\) называется базисом в \(Q\), если
% 1. \(e_k \in Q; k = \overline{1, s}\)
% 2. система \(E = (e_1, e_2, \ldots, e_s)\) линейно независима
% 3. \(\forall x \in Q \; \exists x_1, \ldots, x_5\), что \(x = \sum_{k = 1}^s x_k e_k\)

% #+begin_proof
% Докажем первое утверждение от противного.

% \begin{equation*}
%     A =
%     \begin{pmatrix}
%         a_{11} & a_{12} & \ldots & a_{1n} \\
%         a_{21} & a_{22} & \ldots & a_{2n} \\
%         \ldots & \ldots & \ldots & \ldots \\
%         a_{m1} & a_{m2} & \ldots & a_{mn} \\
%     \end{pmatrix}
% \end{equation*}

% Если базисные строки линейно независимы, тогда выполняется (\(A_i\) — базисный минор)
% \begin{equation*}
%     A_i = \alpha_1 A_{1} + \ldots + \alpha_{i - 1} A_{i - 1} + \alpha_{i + 1} A_{i + 1} + \ldots \alpha_{m} A_{m}
%     \implies
%     \det A_i = 0.
% \end{equation*}
% Получили противоречие с определением базисного минора.

% \begin{equation*}
%     \underset{m \times n}{A} =
%     \begin{pmatrix}
%         a_{11} & \ldots & a_{1r} & \ldots & a_{1n} \\
%         a_{21} & \ldots & a_{2r} & \ldots & a_{2n} \\
%         \ldots & \ldots & \ldots & \ldots & \ldots \\
%         a_{r1} & \ldots & a_{rr} & \ldots & a_{rn} \\
%         \ldots & \ldots & \ldots & \ldots & \ldots \\
%         a_{m1} & \ldots & a_{mr} & \ldots & a_{mn} \\
%     \end{pmatrix}
% \end{equation*}

% Докажем второе утверждение. Рассмотрим произвольный определитель \((r+1)\)-го порядка (к базисному определителю добавили \(\forall i\)-ю строку и \(j\)-й столбец):
% \begin{equation*}
%     \det =
%     \begin{pmatrix}
%         a_{11} & \ldots & a_{1r} & a_{1j} \\
%         a_{21} & \ldots & a_{2r} & a_{2j} \\
%         \ldots & \ldots & \ldots & \ldots \\
%         a_{r1} & \ldots & a_{rr} & a_{rj} \\
%         a_{i1} & \ldots & a_{ir} & a_{ij} \\
%     \end{pmatrix}
% \end{equation*}

% - Если \(i \leq r\) (\(j \leq r\)), то определитель содержит две одинаковых строки (столбца), а значит этот определитель равен нулю.
% - Если \(i > r\) (\(j > r\)), то порядок минора равен \((r + 1)\), а значит определитель такого минора равен нулю.

% Вычислим определитель разложением по \(j\)-му столбцу:
% \begin{equation*}
%     \det = a_{1j} A_{1j} + a_{2j} A_{2j} + \ldots + a_{rj} A_{rj} + a_{ij} A_{ij} = 0
% \end{equation*}

% Так как \(A_{ij}\) — базисный минор, неравный нулю, следовательно
% \begin{equation*}
%     a_{ij} = -\frac{A_{1j}}{A_{ij}} a_{1j} - \frac{A_{2j}}{A_{ij}} a_{2j} - \ldots - \frac{A_{rj}}{A_{ij}} a_{rj}.
% \end{equation*}

% \(a_{ij}\) (элемент \(i\)-й строки) — есть линейная комбинация элементов \(r\) базисных строк.
% #+end_proof









% #+attr_latex: :options [о ФСР]
% #+begin_theorem
% Если ранг \(r\) матрицы коэффициентов ОСЛУ меньше числа неизвестных, то эта система имеет ФСР размерностью \((n - r)\).
% #+end_theorem

% #+begin_proof
% Выразим \(r\) базисных переменных через \((n - r)\) свободных:
% \begin{equation*}
%     \begin{cases}
%         a_{11} x_1 + \ldots + a_{1r} x_r = - a_{1,r + 1} x_{r + 1} - \ldots - a_{1n} x_n \\
%         \ldots + \ldots + \ldots = \ldots - \ldots - \ldots \\
%         a_{r1} x_1 + \ldots + a_{rr} x_r = - a_{r,r + 1} x_{r + 1} - \ldots - a_{rn} x_n \\
%     \end{cases}
% \end{equation*}

% Базисный минор
% \begin{equation*}
%     M_r =
%     \begin{vmatrix}
%         a_{11} & a_{12} & \ldots & a_{1r} \\
%         a_{21} & a_{22} & \ldots & a_{2r} \\
%         \ldots & \ldots & \ldots & \ldots \\
%         a_{r1} & a_{r2} & \ldots & a_{rr} \\
%     \end{vmatrix}
%     \neq 0.
% \end{equation*}

% Базисные переменные \(x_1; \ldots; x_r\) находятся однозначно, если остальным свободным \(x_{r + 1}, \ldots, x_n\) придать числовые значения.

% \begin{equation*}
%     \underbrace{
%         \begin{pmatrix}
%             1 \\
%             0 \\
%             \ldots \\
%             0
%         \end{pmatrix}
%         \quad
%         \begin{pmatrix}
%             0 \\
%             1 \\
%             \ldots \\
%             0
%         \end{pmatrix}
%         \quad
%         \begin{pmatrix}
%             0 \\
%             0 \\
%             \ldots \\
%             1
%         \end{pmatrix}
%     }{\text{всего \((n - r)\) наборов}}
% \end{equation*}

% Подставив первый набор (\(x_{r + 1} = 1, x_{r + 2} = 0, \ldots, x_n = 0\)), получим
% \begin{equation*}
%     \begin{cases}
%         a_{11} x_1 + \ldots + a_{1r} x_r = -a_{1, r + 1} \\
%         \ldots + \ldots & \ldots = \ldots \\
%         a_{11} x_1 + \ldots + a_{rr} x_r = -a_{r, r + 1} \\
%     \end{cases}
% \end{equation*}

% Эта система имеет единственное решение. Так сделаем для каждого набора и получим
% \begin{equation*}
%     X_1 =
%     \begin{pmatrix}
%         x_1^1 \\
%         x_2^1 \\
%         \ldots \\
%         x_r^1 \\
%         1 \\
%         0 \\
%         \ldots \\
%         0
%     \end{pmatrix};
%     \quad
%     X_2 =
%     \begin{pmatrix}
%         x_1^2 \\
%         x_2^2 \\
%         \ldots \\
%         x_r^2 \\
%         1 \\
%         0 \\
%         \ldots \\
%         0
%     \end{pmatrix};
%     \quad
%     \ldots
%     \quad
%     X_{n - r} =
%     \begin{pmatrix}
%         x_1^{n - r} \\
%         x_2^{n - r} \\
%         \ldots \\
%         x_r^{n - r} \\
%         1 \\
%         0 \\
%         \ldots \\
%         0
%     \end{pmatrix};
% \end{equation*}

% Полученная система будет являться ФСР (линейно независима).

% Докажем линейную независимость \(X_1, \ldots, X_{n - r}\). Рассмотрим линейную комбинацию:
% \begin{equation*}
%     \alpha_1 X_1 + \ldots \alpha_{n - r} X_{n - r} = 0.
% \end{equation*}

% Матрица коэффициентов
% \begin{equation*}
%     \begin{pmatrix}
%         x_1^1 & \ldots & x_1^{n - r} \\
%         \ldots & \ldots & \ldots \\
%         x_r^1 & \ldots & x_r^{n - r} \\
%         1 & \ldots & 0 \\
%         \ldots & \ldots & \ldots \\
%         0 & \ldots & 1 \\
%     \end{pmatrix}
% \end{equation*}

% Минор с единицами и нулями \(M_{n - r} = 1 \neq 0\). Определитель не равен нулю, значит ОСЛУ имеет единственное тривиальное решение. Следовательно \(X_1, \ldots, X_{n - r}\) — линейно независима.

% Рассмотрим произвольное решение:
% \begin{equation*}
%     X =
%     \begin{pmatrix}
%         x_1 \\
%         \ldots \\
%         x_r \\
%         x_{r + 1} \\
%         \ldots \\
%         x_n
%     \end{pmatrix};
%     \qquad
% \end{equation*}
% и матрицу \(Y\)
% \begin{equation*}
%     Y = X - x_{r + 1} X_1 - x_{r + 2} X_2 - \ldots - x_n X_{n - r}.
% \end{equation*}
% \begin{equation*}
%     Y =
%     \begin{pmatrix}
%         x_1 \\
%         x_2 \\
%         x_r \\
%         x_{r + 1} \\
%         \ldots \\
%         x_n
%     \end{pmatrix}
%     - x_{r + 1}
%     \begin{pmatrix}
%         x_1^1 \\
%         x_2^1 \\
%         x_r^1 \\
%         1 \\
%         \ldots \\
%         0
%     \end{pmatrix}
%     - \ldots - x_n
%     \begin{pmatrix}
%         x_1^{n - r} \\
%         x_2^{n - r} \\
%         x_r^{n - r} \\
%         0 \\
%         \ldots \\
%         1
%     \end{pmatrix}
% \end{equation*}

% \(Y\) — столбец решений ОСЛУ. Значит решение равносильной системы \((*)\) (однородная и имеет единственное решение), следовательно
% \begin{equation*}
%     Y =
%     \begin{pmatrix}
%         0 \\
%         \ldots \\
%         0
%     \end{pmatrix}
% \end{equation*}

% Тогда
% \begin{equation*}
%     X = x_{r + 1} X_1 + x_{r + 2} X_2 + \ldots + x_n X_{n - r}.
% \end{equation*}
% #+end_proof


% \(Q \sub L \), \(Q\) — произвольное множество векторов линейного пространства.

% Если \(Q \sub L\) обладает базисами, то все они состоят из одинакового числа векторов, называемого рангом (\(\rang Q\)).

% Если пространство \(L\) имеет базис, то оно называется конечномерным (\(L_{n}\), где \(n = \dim L\), т. е. число векторов в любом базисе). В противном случае пространство бесконечномерное.

% Пусть \(L_{n}\) — произвольное \(n\)-мерное пространство. \(B = (e_{1}, \ldots, e_{n})\) — базис в нем. Тогда всякому вектору \(x \in L_{n}\) взаимно однозначно соответствует столбец в этом базисе, то есть
% \begin{equation*}
%     x = x_{1} e_{1} + \ldots + x_{n} e_{n}
%     \iff X =
%     \begin{pmatrix}
%         x_{1}  \\
%         \ldots \\
%         x_{n}
%     \end{pmatrix}
% \end{equation*}

% \begin{equation*}
%     z = x + y \iff Z = X + Y
% \end{equation*}

% \begin{equation*}
%     y = \lambda x \iff Y = \lambda X
% \end{equation*}

% Пусть \(B = (e_{1}, \ldots, e_{n})\), \(B' = (e'_{1}, \ldots, e'_{n})\) — два различных базиса. Каждый из векторов базиса \(B'\) разложим по \(B\):
% \begin{equation*}
%     e'_{k} = t_{1k} e_{1} + \ldots + t_{nk} e_{n}
%     \iff
%     E'_{k} =
%     \begin{pmatrix}
%         t_{1k} \\
%         \ldots \\
%         t_{nk}
%     \end{pmatrix},
%     k = \overline{1, n}.
% \end{equation*}

% Матрица перехода:
% \begin{equation*}
%     T_{B \to B'} =
%     \begin{pmatrix}
%         t_{11} & \ldots & t_{1n} \\
%         \ldots & \ldots & \ldots \\
%         t_{1n} & \ldots & t_{nn}
%     \end{pmatrix}
% \end{equation*}
% \(k\)-ый столбец которой есть столбец \(E'_{k}\) координат \(e'_{k}\) в базисе \(B\).

% Если \(x\) — произвольный вектор из \(L_{n}\), \(X\) и \(X'\) — столбцы координат в базисах \(B\) и \(B'\), то имеет место равенство
% \begin{equation*}
%     X' = (T_{B \to B'})^{-1} X.
% \end{equation*}

% TODO: общее решение ОСЛУ
% TODO: фундаментальная система решений ОСЛУ

% \section{Подпространства и линейное многообразие}

% \begin{definition}
%     Подпространством линейного векторного пространства \(L\) называется подмножество \(L' \sub L\), которое обладает следующими свойствами:
%     \begin{enumerate}
%         \item \(x, y \in L' \implies x + y \in L'\)
%         \item \(x \in L' \implies \lambda x \in L' (\forall lambda)\)
%     \end{enumerate}

%     Если \(L'\) — подпространство в \(L\), то множество векторов
%     \begin{equation*}
%         L' + x_{0} =
%         \big{ x \in L \big| x = x' + x_{0}, x' \in L', x_{0} \in L \big}.
%     \end{equation*}
%     называется линейным многообразием, полученное сдвигом подпространства \(L'\) на вектор \(x_{0}\).
% \end{definition}

% TODO -----------------------------------------------------

\chapter{Линейные операторы}

\section{Определение линейного оператора}

\begin{definition}
    Правило \(f\), по которому каждому элементу \(x\) некоторого непустого множества \(X\) ставится в соответствие единственный элемент \(y\) непустого множества \(Y\), называют \textbf{отображением} (или \textbf{оператором}) множества \(X\) в множество \(Y\). Результат \(y\) применения оператора \(f\) к элементу \(x\) обозначают
    \[
        y = f(x)
    \]
    и говорят, что оператор \(f\), действует из \(X\) в \(Y\) или отображает \(X\) в \(Y\), записывая это в виде
    \[
        f: X \to Y.
    \]
    Элемент \(y\) называют \textbf{образом} элемента \(x\) при действии оператора \(f\), а элемент \(x\) — \textbf{прообразом} элемента \(y\).
\end{definition}

\begin{definition}
    Пусть \(V\) и \(W\) — линейные пространства (либо оба вещественные, либо оба комплексные). Тогда отображение \(\mathcal{A}: V \to W\) называют \textbf{линейным отображением} или \textbf{линейным оператором}, если выполняются следующие условия:
    \begin{enumerate}
        \item \(\forall x \in V; \forall \lambda \in \mathbb{R} \implies \mathcal{A} (\lambda x) = \lambda \mathcal{A} x\);
        \item \(\forall x_1, x_2 \in X \implies \mathcal{A} x + \mathcal{A} y\).
    \end{enumerate}
    Эти два условия можно объединить:
    \[
        \forall x_1, x_2 \in V; \forall \alpha, \beta \in \mathbb{R}
        \implies
        \mathcal{A} (\alpha x_1 + \beta x_2) = \alpha \mathcal{A} x_1 + \beta \mathcal{A} x_2.
    \]
\end{definition}

\begin{definition}
    Линейные операторы \(\mathcal{A}: V \to W\) и \(\mathcal{B}: V \to W\) называют \textbf{равными}, если
    \[
        \forall x, y \in V
        \implies
        \mathcal{A} x = \mathcal{B} x.
    \]
\end{definition}

\begin{definition}
    Линейный оператор \(\mathcal{A}\), который осуществляет отображение линейного пространства \(V\) в себя, также называют \textbf{линейным преобразованием} линейного пространства. В этом случае говорят, что линейный оператор \(\mathcal{A}\) действует в линейном пространстве \(V\), и записывают
    \[
        \mathcal{A}: V \to V.
    \]
\end{definition}

\begin{definition}
    Оператор \(E: V \to V\) называется \textbf{тождественным}, если
    \[
        \forall x \in V \implies E x = x.
    \]
\end{definition}

\begin{definition}
    Оператор \(\Theta: V \to V\) называется \textbf{нулевым}, если
    \[
        \forall x \in V \implies \Theta x = \theta.
    \]
\end{definition}

\begin{definition}
    Линейный оператор \(\mathcal{A}\) называют \textbf{невырожденным}, если из равенства \(\mathcal{A} x = \theta\) следует, что \(x = \theta\). В противном случае линейный оператор \(\mathcal{A}\) называют \textbf{вырожденным}.
\end{definition}

\section{Примеры линейных операторов}

\subsection{Преобразование подобия}

Каждому элементу \(x\) из пространства \(V\) по некоторому правилу ставится в соответствие элемент \(\lambda x\) из \(V\) (\(\lambda \neq 0\) и фиксировано), т. е. имеет место равенство \(\mathcal{A} x = \lambda x\).

\subsection{Оператор поворота}

Оператора поворота на угол \(\varphi\), действующий в пространстве \(V^2\) векторов на плоскости, поворачивает каждый вектор на угол \(\varphi\). Поворот происходит против хода часовой стрелки, если \(\varphi > 0\), и по ходу часовой стрелки, если \(\varphi < 0\).

\subsection{Оператор дифференцирования}

Оператор дифференцирования \(\dfrac{d}{dx}\), действующий в линейном пространстве \(K^n\) многочленов одной переменной \(x\) степени, не превосходящей \(n \in \mathbb{N}\). Каждому многочлену \(P(x)\) ставится в соответствие его производная \(P'(x)\), являющаяся многочленом степени не выше \(n - 1\), т. е. \(P'(x)\) — элемент того же пространства \(K^n\):
\[
    \frac{d}{dx} P(x) = P'(x).
\]
Заметим, что производная суммы функций равна сумме производных, а при умножении функции на число производная этой функции умножается на это число.

\subsection{Оператор интегрирования}

Пусть задано пространство, в котором элементами являются непрерывные функции \(\varphi(t), t \in [0, 1]\). Положим, что
\[
    \mathcal{A} \varphi(t) = \int\limits_0^t \varphi(\tau) d\tau.
\]
Преобразование \(\mathcal{A}\) — линейное, поскольку в силу свойств определенного интеграла имеем
\[
    \mathcal{A} (\varphi_1 + \varphi_2) =
    \int\limits_0^t [\varphi_1(\tau) + \varphi_2(\tau)] d\tau =
    \int\limits_0^t \varphi_1(\tau) d\tau + \int\limits_0^t \varphi_2(\tau) d\tau =
    \mathcal{A} \varphi_1 + \mathcal{A} \varphi_2;
\]

\[
    \mathcal{A} (\alpha \varphi) =
    \int\limits_0^t \alpha \varphi(\tau) d\tau = \alpha \int\limits_0^t \varphi(\tau) d\tau = \alpha \mathcal{A} \varphi.
\]

\subsection{Матричный оператор}

Рассмотрим \(n\)-мерное арифметическое пространство \(\mathbb{R}^n\) (пространство матриц-столбцов высотой \(n\)) и прямоугольную матрицу \(\mathcal{A}\) размером \(m \times n\). Каждому столбцу \(X \in \mathbb{R}^n\) поставим в соответствие столбец \(\mathcal{A} X\), имеющий высоту \(m\). Таким образом, определено отображение \(\mathcal{A}: \mathbb{R}^n \to \mathbb{R}^m\), которое является линейным в силу свойств умножения матриц.

\section{Образ и ядро линейного оператора}

\begin{definition}
    \textbf{Образом} линейного оператора \(\mathcal{A}: V \to W\) называют множество всех элементов \(y \in W\) таких, что \(\mathcal{A} x = y\) для некоторого \(x \in V\). Образ обозначается через \(\Ima \mathcal{A}\):
    \[
        \Ima \mathcal{A} = \{y: y = \mathcal{A} x; x \in V\}.
    \]
\end{definition}

\begin{definition}
    \textbf{Ядром} линейного оператора \(\mathcal{A}: V \to W\) называют множество всех элементов \(x \in V\) таких, что \(\mathcal{A}(x) = \theta\). Ядро обозначается через \(\ker \mathcal{A}\):
    \[
        \ker \mathcal{A} = \{x: \mathcal{A} x = \theta; x \in V\}.
    \]
\end{definition}

\begin{theorem}
    Для любого линейного оператора \(\mathcal{A}: V \to W\) образ \(\Ima A\) и ядро \(\ker A\) являются линейными подпространствами в пространствах \(W\) и \(V\) соответственно.
\end{theorem}

\begin{proof}
    Пусть \(y_1\) и \(y_2\) — элементы из \(\Ima \mathcal{A}\). Значит
    \[
        \exists x_1, x_2 \in V: \mathcal{A} x_1 = y_1, \mathcal{A} x_2 = y_2.
    \]
    Из соотношения
    \[
        \lambda_1 y_1 + \lambda_2 y_2 =
        \lambda_1 \mathcal{A} x_1 + \lambda_2 \mathcal{A} x_2 =
        \mathcal{A} (\lambda_1 x_1 + \lambda_2 x_2)
    \]
    следует, что произвольная комбинация элементов \(y_1\) и \(y_2\) также лежит в \(\Ima \mathcal{A}\).

    В тоже время, если \(x_1, x_2 \in \ker \mathcal{A}\), что означает выполнение соотношений \(\mathcal{A} x_1 = \theta\) и \(\mathcal{A} x_2 = \theta\), то
    \[
        \mathcal{A} (\lambda_1 x_1 + \lambda_2) = \lambda_1 \mathcal{A} x_1 + \lambda_2 \mathcal{A} x_2 = \theta + \theta = \theta,
    \]
    т. е. множество \(\ker A\) замкнуто относительно линейных операций и потому является линейных подпространством.
\end{proof}

\begin{definition}
    Размерность образа \(\Ima \mathcal{A}\) линейного оператора \(\mathcal{A}\) называют \textbf{рангом} этого линейного оператора. Обозначают через \(\rang A\).
\end{definition}

\begin{definition}
    Размерность ядра \(\ker \mathcal{A}\) линейного оператора \(\mathcal{A}\) называют \textbf{дефектом} этого линейного оператора. Обозначают через \(\defect \mathcal{A}\).
\end{definition}

\begin{theorem}
    Для любого линейного оператора \(\mathcal{A}: V \to W\) справедливо равенство
    \[
        \rang \mathcal{A} + \defect \mathcal{A} = \dim V.
    \]
\end{theorem}

\begin{theorem}[построение линейного оператора]
    Пусть \(V\) и \(W\) — линейные пространства, \(\{e\} = (e_1, e_2, \ldots, e_n)\) — базис пространства \(V\), а \(g_1, g_2, \ldots, g_n\) — произвольные элементы из пространства \(W\). Тогда
    \[
        \exists! \mathcal{A}: V \to W : \mathcal{A} e_i = g_i, i = \overline{1, n}.
    \]
\end{theorem}

\begin{proof}
    Докажем существование. Разложим произвольный элемент \(x \in V\) по базису \(\{e\}\) пространства \(V\):
    \[
        x = x_1 e_1 + x_2 e_2 + \ldots + x_n e_n = \sum_{i = 1}^n x_i e_i.
    \]
    Построим отображение \(\mathcal{A}: V \to W\) по следующему правилу:
    \[
        \mathcal{A} x =
        \mathcal{A} (x_1 e_1 + \ldots + x_n e_n) =
        x_1 (\mathcal{A} e_1) + \ldots + x_n (\mathcal{A} e_n) =
        \sum_{i = 1}^n x_i (\mathcal{A} e_i) = \sum_{i = 1}^n x_i g_i,
    \]
    т. е., зная элементы \(\mathcal{A} e_i\) можно найти образ любого элемента \(x\) линейного пространства \(V\).

    Убедимся в линейности оператора \(\mathcal{A}\). Пусть
    \[
        x = \sum_{i = 1}^n x_i e_i;
        \qquad
        y = \sum_{i = 1}^n y_i e_i.
    \]
    Тогда:
    \[
        \mathcal{A} (\alpha x + \beta y) =
        \sum_{i = 1}^n (\alpha x_i + \beta y_i) g_i =
        \alpha \sum_{i = 1}^n x_i g_i + \beta \sum_{i = 1}^n y_i g_i =
        \alpha \mathcal{A} x + \beta \mathcal{A} y.
    \]
    Условие линейности оператора выполняется.

    Докажем единственность. Предположим, что
    \[
        \exists \mathcal{B}: V \to W : \mathcal{B} e_i = g_i, i = \overline{1, n}.
    \]
    Тогда
    \[
        \mathcal{A} x =
        \sum_{i = 1}^n x_i g_i =
        \sum_{i = 1}^n x_i \mathcal{B} e_i =
        \mathcal{B} \Big( \sum_{i = 1}^n x_i e_i \Big) =
        \mathcal{B} x.
    \]
    Операторы \(\mathcal{A}\) и \(\mathcal{B}\) совпадают.
\end{proof}

\section{Матрица линейного оператора}

Пусть задан линейный оператор \(\mathcal{A}: V \to V\), т. е. линейное преобразование \(n\)-мерного линейного пространства в себя: \(y = \mathcal{A} x\). Найдем связь между координатами элемента \(x \in V\) и координатами его образа \(y \in V\).

Выберем в пространстве \(V\) базис \(\{e\} = (e_1, e_2, \ldots, e_n)\), и пусть \(x = x_1 e_1 + x_2 e_2 + \ldots + x_n e_n\). Тогда в силу линейности преобразований \(\mathcal{A}\) имеем
\[
    \mathcal{A} x =
    x_1 (\mathcal{A} e_1) + x_2 (\mathcal{A} e_2) + \ldots + x_n (\mathcal{A} e_n) =
    \sum_{i = 1}^n x_i (\mathcal{A} e_i).
\]

Поскольку \(\mathcal{A} e_i\) (\(i = \overline{1,n}\)) — это тоже элемент из \(V\), то и \(\mathcal{A} e_i\) можно разложить по базису:
\[
    \mathcal{A} e_i =
    a_{1i} e_1 + a_{2i} e_2 + \ldots + a_{ni} e_n =
    \sum_{k = 1}^n a_{ki} e_k, \quad i = \overline{1, n}.
\]
Тогда получим
\[
    \mathcal{A} x =
    \sum_{i = 1}^n x_i (A e_i) =
    \sum_{i = 1}^ n x_i \sum_{k = 1}^n a_{ki} e_k =
    \sum_{k = 1}^ n \Big( \sum_{i = 1}^n a_{ki} x_i \Big) e_k.
\]

В силу единственности разложения элемента по базисным элементам \(e_1, e_2, \ldots, e_n\), получим
\[
    \mathcal{A} x =
    y_1 e_1 + y_2 e_2 + \ldots + y_n e_n =
    \sum_{i = 1}^n y_i e_i,
\]
где \(y_1, y_2, \ldots, y_n\) — координаты преобразованного элемента \(\mathcal{A} x\) в базисе \(\{e\}\). Тогда получим
\[
    y_k = \sum_{i = 1}^n a_{ik} x_i,
\]
или в развернутом виде:
\[
    \begin{cases}
        y_1 = a_{11} x_1 + a_{12} x_2 + \ldots + a_{1n} x_n \\
        y_2 = a_{21} x_1 + a_{22} x_2 + \ldots + a_{2n} x_n \\
        \dotfill                                            \\
        y_n = a_{n1} x_1 + a_{n2} x_2 + \ldots + a_{nn} x_n \\
    \end{cases}
\]
Эта формула представляет линейное преобразование \(y = \mathcal{A} x\) в координатной форме.

Элементам \(x\) и \(y\) поставим в соответствие матрицы-столбцы \(X\) и \(Y\), образованные из координат этих элементов в базисе \(\{e\}\):
\[
    X =
    \begin{pmatrix}
        x_1    \\
        x_2    \\
        \ldots \\
        x_n
    \end{pmatrix},
    \quad
    Y =
    \begin{pmatrix}
        y_1    \\
        y_2    \\
        \ldots \\
        y_n
    \end{pmatrix}.
\]
Тогда полученная система уравнений в развернутой матричной форме примет вид
\[
    \begin{pmatrix}
        y_1    \\
        y_2    \\
        \ldots \\
        y_n
    \end{pmatrix}
    =
    \begin{pmatrix}
        a_{11} & a_{12} & \ldots & a_{1n} \\
        a_{21} & a_{22} & \ldots & a_{2n} \\
        \ldots & \ldots & \ldots & \ldots \\
        a_{n1} & a_{n2} & \ldots & a_{nn} \\
    \end{pmatrix}
    \begin{pmatrix}
        x_1    \\
        x_2    \\
        \ldots \\
        x_n
    \end{pmatrix}
\]
или, в сокращенной форме,
\[
    Y = AX.
\]
Здесь \(A\) — квадратная матрица, у которой \(i\)-й столбец образован коэффициентами разложения элемента \(\mathcal{A} e_i\) по базису \(\{e\}\).

Таким образом, показано, что при заданном базисе любое линейное преобразование можно представить, и притом единственным способом, в матричной форме, т. е. по своей структуре линейный оператор есть некоторая матрица.

\begin{definition}
    Матрицу \(A\), составленную из координатных столбцов элементов \(\mathcal{A} e_i\) (\(i = \overline{1, n}\)) в базисе \(\{e\} = (e_1, e_2, \ldots, e_n)\) называют \textbf{матрицей линейного оператора} \(\mathcal{A}\) в базисе \(\{e\}\).
\end{definition}

\begin{definition}
    Матрица линейного оператора \(\mathcal{A}: V \to V\) называется \textbf{квадратной}, если ее порядок совпадает с размерностью линейного пространства \(V\).
\end{definition}

\begin{theorem}
    Каждая квадратная матрица \(A\) порядка \(n\) может рассматриваться как матрица некоторого линейного оператора \(\mathcal{A}\), следовательно, всякое преобразование вида \(Y = AX\) является линейным преобразованием.
\end{theorem}

\begin{proof}
    В силу свойств операции умножения матриц:
    \[
        \forall X_1, X_2, \lambda_1, \lambda_2
        \implies
        A(\lambda_1 X_1 + \lambda_2 X_2) = \lambda_1 A X_1 + \lambda_2 A X_2.
    \]

    Таким образом, при фиксированном базисе между линейным преобразованием и матрицей линейного преобразования установлено взаимно-однозначное соответствие, что позволяет отождествлять преобразование \(\mathcal{A}\) с его матрицей \(A\) и записывать линейное преобразование \(y = \mathcal{A} x\) в матричной форме \(Y = AX\) или в координатной форме.
\end{proof}

\begin{theorem}
    Ранг матрицы \(A\) линейного оператора \(\mathcal{A}: V \to V\) совпадает с рангом этого оператора.
\end{theorem}

\begin{proof}
    Пусть \(\{e\} = (e_1, e_2, \ldots, e_n)\) — некоторый базис линейного пространства \(V\). Образ \(\Ima \mathcal{A}\) линейного оператора \(\mathcal{A}\) представляет собой \textbf{линейную оболочку} системы элементов \(\mathcal{A} e_1, \mathcal{A} e_2, \ldots, \mathcal{A} e_n\), то есть
    \[
        \Ima \mathcal{A} = L(\mathcal{A} e_1, \mathcal{A} e_2, \ldots, \mathcal{A} e_n).
    \]

    При этом \(\rang \mathcal{A}\) равен максимальному число линейно независимых элементов в системе \(\mathcal{A} e_1, \mathcal{A} e_2, \ldots, \mathcal{A} e_n\) и совпадает с максимальным числом линейно независимых столбцов в матрице \(A\), т. е. с ее рангом. Таким образом,
    \[
        \rang A = \rang \mathcal{A}.
    \]
\end{proof}

\section{Примеры матриц линейных операторов}

\subsection{Нулевой оператор}

Пусть \(\Theta : V \to V\) — нулевой оператор. Матрицей такого оператора независимо от выбора базиса является нулевая матрица \(\theta\) соответствующего типа. Действительно, в случае нулевого оператора любой элемент будет нулевым. Поэтому матрица нулевого оператора в любом базисе состоит из нулевых столбцов.

\subsection{Тождественный оператор}

Пусть \(\mathcal{E}: V \to V\) — тождественный оператор, действующий согласно правилу
\[
    \forall x \implies \mathcal{E} x = x
\]
Тогда \(\mathcal{E} e_i = e_i\) для всех \(i = \overline{1, n}\) и, следовательно, матрица оператора \(\mathcal{E}\) в любом базисе является единичной:
\[
    E =
    \begin{pmatrix}
        1      & 0      & \ldots & 0      \\
        0      & 1      & \ldots & 0      \\
        \ldots & \ldots & \ldots & \ldots \\
        0      & 0      & \ldots & 1      \\
    \end{pmatrix}
\]

\subsection{Поворот трехмерного пространства}

Пусть \(\mathcal{A}\) — поворот трехмерного пространства на угол \(\varphi\) вокруг оси \(Oz\). Если \(e_1, e_2, e_2\) — единичные векторы прямоугольной декартовой системы координат, то
\begin{gather*}
    \mathcal{A} e_1 = \cos \varphi \cdot e_1 + \sin \varphi \cdot e_2; \\
    \mathcal{A} e_2 = - \sin \varphi \cdot e_1 + \cos \varphi \cdot e_2; \\
    \mathcal{A} e_3 = e_3
\end{gather*}
и, значит, матрица этого оператора будет иметь вид
\[
    A =
    \begin{pmatrix}
        \cos \varphi & - \sin \varphi & 0 \\
        \sin \varphi & \cos \varphi   & 0 \\
        0            & 0              & 1
    \end{pmatrix}
\]

\section{Действия над линейными операторами}

\subsection{Сложение линейных операторов}

\begin{lemma}
    Пусть \(\mathcal{A}: V \to W\) и \(\mathcal{B}: V \to W\) — линейные операторы. Тогда \textbf{суммой линейных операторов} \(\mathcal{A}\) и \(\mathcal{B}\) называют оператор \(\mathcal{C}: V \to W\) такой, что
    \[
        \forall x \in V
        \implies
        \mathcal{C} x = \mathcal{A} x + \mathcal{B} x.
    \]
\end{lemma}

\begin{proof}
    Линейность оператора \(\mathcal{C}\) можно доказать следующим образом:
    \begin{gather*}
        \mathcal{C} (\lambda_1 x + \lambda_2 y) =
        \mathcal{A} (\lambda_1 x + \lambda_2 y) + B (\lambda_1 x + \lambda_2 y) = \\ =
        \lambda_1 (\mathcal{A} x + \mathcal{B} x) + \lambda_2 (\mathcal{A} y + \mathcal{B} y) =
        \lambda_1 \mathcal{C} x + \lambda_2 \mathcal{C} y.
    \end{gather*}
\end{proof}

\subsection{Свойства сложения линейных операторов}

\begin{property}
    \[
        \mathcal{A} + \mathcal{B} = \mathcal{B} + \mathcal{A}
    \]
\end{property}

\begin{property}
    \[
        (\mathcal{A} + \mathcal{B}) + \mathcal{C} = \mathcal{A} + (\mathcal{B} + \mathcal{C}).
    \]
\end{property}

\begin{property}
    \[
        \mathcal{A} + \Theta = \mathcal{A}.
    \]
\end{property}

\begin{property}
    \[
        \mathcal{A} + (- \mathcal{A}) = \Theta.
    \]
\end{property}

\subsection{Умножение оператора на число}

\begin{lemma}
    \textbf{Произведением линейного оператора} \(\mathcal{A}: V \to W\) и числа \(\alpha\) называют такой оператор \(\mathcal{B}: V \to W\), что \[
        \forall x \in V
        \implies
        \mathcal{B} x = \alpha \mathcal{A} x.
    \]
\end{lemma}

\begin{proof}
    Линейность оператора \(\mathcal{B}\) можно доказать следующим образом:
    \[
        \mathcal{B} (\lambda_1 x_1 + \lambda_2 x_2) =
        \alpha \mathcal{A} (\lambda_1 x_1 + \lambda_2 x_2) =
        \lambda_1 (\alpha \mathcal{A} x_1) + \lambda_2 (\alpha \mathcal{A} x_2) =
        \lambda_1 \mathcal{B} x_1 + \lambda_2 \mathcal{B} x_2.
    \]
\end{proof}

\subsection{Свойства умножения линейного оператора на число}

\begin{property}
    \[
        1 \cdot \mathcal{A} = \mathcal{A}.
    \]
\end{property}

\begin{property}
    \[
        \alpha (\beta \mathcal{A}) = (\alpha \beta) \mathcal{A}.
    \]
\end{property}

\begin{property}
    \[
        (\alpha + \beta) \mathcal{A} = \alpha \mathcal{A} + \beta \mathcal{A}.
    \]
\end{property}

\begin{property}
    \[
        \alpha (\mathcal{A} + \mathcal{B}) = \alpha \mathcal{A} + \alpha \mathcal{B}.
    \]
\end{property}

% \section{Матрицы линейного оператора в разных базисах}

% Пусть \(A\) — линейный оператор в конечномерном пространстве \(L_{n}\) и \(B = (e_{1}, \ldots, e_{n})\) — некоторый фиксированный базис. Разложим векторы \(A_{e_{k}}\) \(k = \overline{1, k}\) по базису \(B\):
% \begin{equation*}
%     A_{e_{k}} = a_{1k} e_{1} + \ldots + a_{nk} e_{n}.
% \end{equation*}

% Тогда
% \begin{equation*}
%     A =
%     \begin{pmatrix}
%         a_{11} & a_{12} & \ldots & a_{1n} \\
%         a_{21} & a_{22} & \ldots & a_{2n} \\
%         \ldots & \ldots & \ldots & \ldots \\
%         a_{n1} & a_{n2} & \ldots & a_{nn}
%     \end{pmatrix}
% \end{equation*}
% матрица оператора \(A\) в базисе \(B\). Обозначается \([A]\) или \([A]_{B}\). Оператор определяется однозначно заданием матрицы \(A\).

% Пусть \(A\) и \(A'\) — матрицы оператора \(A\) в базисах \(B\) и \(B'\). \(T = T_{B \to B'}\), тогда \(A' = T^{-1} AT\) — формула преобразования матрицы оператора при преобразовании базиса.

% % TODO: надо снизу?
% % Обозначим столбцы за \(g_{1}, g_{2}, \ldots, g_{n}\). \({e_{1}, \ldots, e_{n}} \forall x \in L\). \(x \xi_{1} e_{1} + \ldots \xi_{n} e_{n}\).
% % \begin{equation*}
% %     Ax = \xi_{1} Ae_{1} + \ldots + \xi_{n} Ae_{n} = \xi_{1} g_{1} + \ldots + \xi_{n} g_{n}.
% %   \end{equation*}


% \begin{definition}
%     Матрица \(A\) называется \textbf{подобной} матрице \(B\), если существует такая невырожденная матрица \(C\), что
%     \[
%         A = C^{-1} B C.
%     \]
% \end{definition}

% \begin{definition}
%     Пусть число \(\lambda\) и вектор \(x \in L: x \neq 0\) таковы, что \(Ax = \lambda x\). Тогда \(\lambda\) называется собственным числом оператора \(A\), а \(X\) — собственным вектором, соответствующий собственному числу.
% \end{definition}

% TODO: сопряженный и самосопряженный вектор


% \section{Квадратичная форма}

% Квадратичной формой \(f(x_1, x_2, \ldots, x_n)\) \(n\) переменных называется
% \begin{align}
%     \sum_{i = 1}^n \sum_{j = 1}^n a_{ij} x_i x_j =
%     \sum_{n}^{j = 1} a_{ii} x_i^2 + \sum_{i < j} a_{ij} x_i x_j.
% \end{align}

% \(a_{ij}\) — коэффициенты квадратичной формы; числа, среди которых хотя бы одно отлично от нуля.

% Квадратичная форма имеет канонический вид, если \(a_{ij} = 0\) при \(i \neq j\).

% \[
%     \sum_{i = 1}^n \sum_{j = 1}^n = a_{ij} x_i x_j =
%     a_{11} x_1^2 + a_{22} x_2^2 + \ldots + a_{nn} x_n^2.
% \]

% Так как \(x_i x_j = x_j x_i\), то и \(a_{ij} = a_{ji}\) (считается).

% \[
%     f(x_1, x_2, x_3) =
%     a_{11} x_1^2 + 2 a_{12} x_1 x_2 + 2_{13} x_1 x_3 + 2 a_{23} x_2 x_3 + a_{22} x_2^2 + a_{33} x_3^2 =
%     X^T A X.
% \]

% Симметричная (\(a_{ij} = a_{ji}\))
% \[
%     A =
%     \begin{pmatrix}
%         a_{11} & a_{12} & a_{13} \\
%         a_{12} & a_{22} & a_{23} \\
%         a_{13} & a_{23} & a_{33}
%     \end{pmatrix}
% \]

% Канонический вид
% \[
%     A' =
%     \begin{pmatrix}
%         a_{11}' & 0       & 0      \\
%         0       & a_{22}' & 0      \\
%         0       & 0       & a_{33}
%     \end{pmatrix}
% \]

% \[
%     f(x_1, x_2, x_3) = a_{11}' x_1^n + a_{22}' x_2^2 + a_{33}' x_3^2.
% \]

% \section{Приведение квадратичной формы к каноническому виду}

% Рассмотрим \(f(x_1, x_2, \ldots, x_n) = X^T A X\). \(T\) — преобразование координат, \(T\) — ортогональная матрица:
% \[
%     T^{-1} = T^T.
% \]

% \[
%     \det T = \pm 1.
% \]

% \[
%     X = TX'.
% \]

% \[
%     f(x_1', x_2', \ldots, x_n') = X^T A X = (TX')^T A (TX') = (X')^T T^T A T X' = (X')^T A' X',
% \]
% где \(A' = T^T A T = T^{-1} A T\).

% \[
%     (A')^T = (T^T A T)^T = (T^T (A T))^T (AT)^T (T^T)^T = T^T A^T T = A'
%     \implies
%     (A')^T = A'
% \]
% Значит \(A'\) — симметрическая матрица. Следовательно, ей соответствует самосопряженный оператор. Если базис этого оператора будет состоять из единичных векторов, тогда матрица получится диагональной (т. е. на диагонали собственные числа).

% \section{Алгоритм приведения квадратичной формы к каноническому виду}

% \begin{enumerate}
%     \item найти собственные числа матрицы \(A\);
%     \item найти собственные векторы и нормировать их;
%     \item составить матрицу преобразования координат \(T = (\hat{e}_1, \hat{e}_2, \ldots, \hat{e}_n)\) так, чтобы \(\det T = 1\);
%     \item найти матрицу канонической формы (\(\lambda_i\) - собственные числа матрицы \(A\)):
%           \[
%               A' = T^T A T =
%               \begin{pmatrix}
%                   \lambda_1 & 0         & \ldots & 0         \\
%                   0         & \lambda_2 & \ldots & 0         \\
%                   \ldots    & \ldots    & \ldots & \ldots    \\
%                   0         & 0         & \ldots & \lambda_n \\
%               \end{pmatrix};
%           \]
%     \item канонический вид: \(f(x_1, x_2, \ldots, x_n) = \lambda_1 x_1^2 + \lambda_2 x_2^2 + \ldots + \lambda_n x_n^2\).
% \end{enumerate}

% \[
%     f(x_1, x_2) = x_1 x_2
% \]

% \[
%     A =
%     \begin{pmatrix}
%         0           & \frac{1}{2} \\
%         \frac{1}{2} & 0           \\
%     \end{pmatrix}
% \]

% \[
%     |A - \lambda E| =
%     \begin{vmatrix}
%         0 - \lambda & \frac{1}{2} \\
%         \frac{1}{2} & 0 - \lambda \\
%     \end{vmatrix}
%     = \lambda^2 - \frac{1}{4} = 0
%     \implies
%     \lambda{1, 2} = \pm \frac{1}{2}.
% \]

% \[
%     \lambda_1 = \frac{1}{2}
% \]

% \[
%     - \frac{1}{2} \xi_1' + \frac{1}{2} \xi_2' = 0
%     \implies
%     \xi_1' = \xi_2'.
% \]

% \[
%     \xi_1 = 1; \xi_2 = 1.
% \]

% \chapter{Дифференциальные уравнения}

% TODO: определение дифференциального уравнения
% Дифференциальным уравнением называется уравнение, которое связывает независимую переменную \(x\), функцию \(F(x, )\)


% \begin{definition}
%     Пусть \(A\) — матрица линейного оператора \(\mathcal{A}\). Матрица \(\lambda E - A\) называется \textbf{характеристической матрицей} линейного оператора, уравнение \(|\lambda E - A| = 0\) — \textbf{характеристическим уравнением}. Таким образом, если \(X\) обственный вектор, то число \(\lambda\) является характеристическим корнем.
% \end{definition}

\chapter{Дифференциальные уравнения}

\section{Основные определения}

Дифференциальное уравнение называется \textbf{обыкновенным}, если оно содержит производные от искомой функции только по одной переменной:

\textbf{Порядком} дифференциального уравнения называется порядок старшей производной, входящей в это уравнение.

\textbf{Обыкновенным дифференциальным уравнением первого порядка} называется соотношение, связывающее искомую функцию, ее аргумент и первую производную от искомой функции:
\begin{equation}
    \label{eq:обыкновенная-диффура}
    F(x, y, y') = 0,
\end{equation}
где \(y\) -- искомая функция, \(x\) -- ее аргумент, а \(y' = dy / dx\).

\label{def:диффура-в-нормальной-форме}
Если уравнение \eqref{eq:обыкновенная-диффура} можно переписать в виде
\begin{equation}
    \label{eq:диффура-в-нормальной-форме}
    y' = f(x, y),
\end{equation}
то уравнение \eqref{eq:диффура-в-нормальной-форме} называется уравнением, \textbf{разрешенным относительно производной}, или уравнением \textbf{в нормальной форме}.

В некоторых случаях возникает необходимость использовать \textbf{перевернутое уравнение}:
\begin{equation}
    \label{eq:перевернутая-диффура}
    \frac{dx}{dy} = \frac{1}{f(x, y)},
\end{equation}
В место двух уравнений \eqref{eq:диффура-в-нормальной-форме} и \eqref{eq:перевернутая-диффура} можно использовать одно уравнение, записанное в форме
\begin{equation}
    \label{eq:частный-случай-уравнения-в-диффурах}
    dy - f(x, y)dx = 0.
\end{equation}

Уравнение \eqref{eq:частный-случай-уравнения-в-диффурах} содержит не производную искомой функции, а дифференциалы от ее аргументов. Это частый случай уравнения, записанного в дифференциалах. В общем случае \textbf{уравнение в дифференциалах} имеет вид:
\begin{equation}
    \label{eq:общий-случай-уравнения-в-диффурах}
    M(x, y) dx + N(x, y) dy = 0.
\end{equation}

В уравнениях \eqref{eq:частный-случай-уравнения-в-диффурах} и \eqref{eq:общий-случай-уравнения-в-диффурах} переменные \(x\) и \(y\) входят равноправно. Запись уравнения в виде \eqref{eq:общий-случай-уравнения-в-диффурах} показывает, что при решении дифференциального уравнения первого порядка любую величину \(x\) или \(y\) можно рассматривать в качестве аргумента, а другую -- принять за искомую функцию.

Уравнение \textbf{в симметрической форме} выглядит следующим образом:
\begin{equation}
    \frac{dx}{M(x, y)} = \frac{dy}{N(x, y)}.
\end{equation}

\section{Задача Коши}

Одной из важнейших задач в теории дифференциальных уравнений является так называемая задача Коши. Для уравнения
\begin{equation}
    \label{eq:уравнение-коши}
    \frac{dy}{dx} = f(x, y),
\end{equation}
\textbf{задача Коши} или \textbf{начальная задача} ставится следующим образом: среди всех решений уравнения найти такое решение, которое будет удовлетворять условию:
\begin{equation}
    y(x_0) = y_0,
\end{equation}
где \(x_0\) и \(y_0\) -- некоторые заданные числа. При этом \(y_0\) называется \textbf{начальным значением} искомой функции, а число \(x_0\) -- \textbf{начальным значением независимой переменной}. В целом же числа \(x_0\) и \(y_0\) называются \textbf{начальными данными}.

Задачу Коши \textbf{геометрически} можно сформулировать так: среди всех интегральных кривых уравнения
\begin{equation}
    \frac{dy}{dx} = f(x, y)
\end{equation}
найти ту, которая проходит через заданную точку \(M_0 (x_0, y_0)\).

Задача Коши с начальными условиями \(x_0\) и \(y_0\) имеет \textbf{единственное решение}, если \(\exists \lambda > 0\) такое, что в интервале \(|x - x_0| \leq \lambda\) определено решение \(y = y(x)\) такое, что \(y(x_0) = y_0\). При этом не существует решения, определенного в этом же интервале и не совпадающего с решением \(y = y(x)\) хотя бы в одной точке интервала \(|x - x_0| \leq \lambda\), отличной от точки \(x = x_0\).

\begin{theorem}
    Непрерывная функция \(y = y(x)\) является решением задачи Коши тогда и только тогда, когда выполняется равенство
    \begin{equation}
        \label{eq:коши-интеграл}
        y = y_0 + \int\limits_{x_0}^x f(t, y(t)) dt.
    \end{equation}

    \begin{proof}
        Докажем необходимость. Пусть \(y = y(x)\) является решением задачи Коши, тогда справедливо тождество
        \[
            y' = f(x, y).
        \]
        Интегрируя это тождество в пределах от \(x_0\) до \(x\) и учитывая условие \(x = x_0\) и \(y = y_0\), получаем требуемое равенство \eqref{eq:коши-интеграл}.

        Докажем достаточность. Так как функции \(y = y(x)\) и \(f(x, y)\) непрерывные, то правая часть равенства \eqref{eq:коши-интеграл}, а следовательно, и левая, будут непрерывно дифференцируемыми по \(x\) функциями. Дифференцируя тождество \eqref{eq:коши-интеграл} получаем, что функция \(y = y(x)\) является решением уравнения задачи Коши. Если в равенстве \eqref{eq:коши-интеграл} положить \(x = x_0\), то увидим, что это уравнение также удовлетворяет условию.
    \end{proof}
\end{theorem}

\chapter{Методы интегрирования уравнений в нормальной форме}

\section{Неполные уравнения}

Дифференциальное уравнение в нормальной форме называется \textbf{неполным}, если его правая часть зависит только от одного аргумента. Рассмотрим уравнение вида
\begin{equation}
    y' = f(x),
\end{equation}
где будем считать функцию \(f(x)\) определенной и непрерывной на некотором интервале \((a, b)\).

Правая часть уравнения не зависит от искомой функции \(y(x)\), поэтому область определения есть множество \(D = (a, b) \times (-\infty, +\infty)\). Поскольку правая часть уравнения не зависит от переменной \(y\), то выполнены условия теоремы Пикара и поэтому имеет место существования и единственность решения начальной задачи.

Преобразуем уравнение:
\begin{gather}
    y' = f(x) \\
    \frac{dy}{dx} = f(x) \\
    dy = f(x)dx \\
    y = \int f(x)dx + C.
\end{gather}

Полученная формула определяет общее решение исходного уравнения на множестве \(R = \{ x \in (a, b); |y| < \infty \}\). Особых решений \(y\) исходного уравнения нет.

Если дополнительно задано начальное условие \(y(x_0) = y_0\),  то решение, удовлетворяющее этому условию, определяется формулой
\begin{equation}
    y(x, x_0, y_0) = y_0 + \int\limits_{x_0}^x f(t)dt.
\end{equation}

При фиксированном \(x_0\) и произвольном \(y_0\) эта формула определяет общее решение исходного уравнения на множестве \(\mathbb{R}\) в форме Коши. Также из этой формы следует, что каждое решение уравнения определено на интервале \((a, b)\) и вся полоса \(\mathbb{R}\) заполнена непересекающимися интегральными кривыми.

Предположим теперь, что для некоторого \(\xi \in (a, b)\) будет \(f(\xi) = \infty\). В окрестности этой точки рассмотрим тогда перевернутое уравнение
\begin{equation}
    \frac{dx}{dy} = \frac{1}{f(x)}.
\end{equation}

Это уравнение определено при \(x = \xi\), более того, очевидно, что прямая \(x \equiv \xi\) -- решение этого уравнения. Это решение может быть как частным, так и особым.

\section{Уравнения с разделяющимися переменными}

Дифференциальное уравнение первого порядка, допускающее приведение к виду
\begin{equation}
    \label{eq:уравнение-с-разделяющимися-переменными}
    f_1(x) \varphi_1(y) dx + f_2(x) \varphi_2(y) dy = 0,
\end{equation}
где \(f_1(x), f_2(x)\) -- известные функции лишь переменной \(x\), а \(\varphi_1(y), \varphi_2(y)\) -- известные функции лишь переменной \(y\), называется уравнением с разделяющимися переменными.

Для решения этого уравнения нужно произвести разделение переменных, т. е. преобразовать это уравнение так, чтобы при \(dx\) стоял бы множитель, зависящий только от \(x\), а при \(dy\) стоял бы множитель, зависящий только от y. Для этого достаточно обе части уравнения разделить на произведение \(f_2(x) \varphi_(y)\):
\[
    \frac{f_1(x)}{f_2(x)} dx + \frac{\varphi_2(y)}{\varphi_1(y)} dy = 0.
\]

Рассматривая для определенности в последнем равенстве \(y\) как функцию переменной \(x\), получим
\[
    \Big[ \frac{f_1(x)}{f_2(x)} + \frac{\varphi_2(y)}{\varphi_1(y)} \cdot y' \Big] dx = 0.
\]

Отсюда, интегрируя по \(x\), будем иметь
\[
    \int \Big[ \frac{f_1(x)}{f_2(x)} + \frac{\varphi_2(y)}{\varphi_1(y)}y' \Big] dx = C.
\]
или
\begin{equation}
    \label{eq:интегральное-уравнение-с-разделяющимися-переменными}
    \int \frac{f_1(x)}{f_2(x)} dx + \int \frac{\varphi_2(y)}{\varphi_1(y)} dy = C,
\end{equation}
где \(C\) -- произвольная постоянная.

Кроме решений, даваемых формулой \eqref{eq:интегральное-уравнение-с-разделяющимися-переменными}, уравнение \eqref{eq:уравнение-с-разделяющимися-переменными} допускает решение, обращающие в ноль произведение \(f_2(x) \varphi_1(y)\), т. е. являющиеся корнями уравнений \(f_2(x) = 0\) или \(\varphi_1(y) = 0\).

В самом деле, пусть \(x = a\), где \(f_2(a) = 0\), тогда \(dx = 0\) (поскольку дифференциал константы \(a\) равен нулю). Подставляя эту функцию в уравнение, получим
\[
    f_1(a) \varphi_1(y) \cdot 0 + f_2(a) \varphi_2(y) dy \equiv 0,
\]
т. е. \(x = a\) -- решение уравнения \eqref{eq:уравнение-с-разделяющимися-переменными}. Аналогично можно показать, что функция \(y = b\), где \(\varphi_1(b) = 0\), является также решением уравнения \eqref{eq:уравнение-с-разделяющимися-переменными}. Геометрически эти решения, если они существуют, составляют собой прямые, параллельные осям координат.

\section{Однородные уравнения}

Функция \(f(x, y)\) называется \textbf{однородной измерения \(\alpha\)}, если при любом значении \(\lambda\) выполняется тождество
\begin{equation}
    f(\lambda x, \lambda y)  = \lambda^{\alpha} f(x, y).
\end{equation}

В частности, многочлен
\[
    P(x, y) = \sum_{i, j} C_{ij} x^i y^i
\]
представляет собой однородную функцию \(n\)-го измерения, если всего его члены имеют одно и тоже измерение, равное \(n\), то есть, если \(i + j = n\).

Дифференциальное уравнение первого порядка
\begin{equation}
    P(x, y) dx + Q(x, y) dy = 0
\end{equation}
называется \textbf{однородным}, если коэффициенты \(P(x, y)\) и \(Q(x, y)\) при дифференциалах переменных \(x\) и \(y\) однородные функции одного и того же измерения.

\section{Линейные уравнения}

Дифференциальное уравнение 1-го порядка называется \textbf{линейным}, если оно первой степени относительно неизвестной функции \(y\) и ее производной \(y'\) (или дифференциала \(dy\)) и не содержит произведения этих величин. В общем случае линейное уравнение имеет вид
\begin{equation}
    \label{eq:линейное-уравнение}
    \alpha(x) y' + \beta(x) y + \gamma(x) = 0,
\end{equation}
где коэффициенты \(\alpha(x)\), \(\beta(x)\) и \(\gamma(x)\) -- данные непрерывные функции в некотором интервале \(x \in (a, b)\).

Предполагая, что \(\alpha(x) \neq 0\), и вводя обозначения
\[
    p(x) = \frac{\beta(x)}{\alpha(x)},
    \qquad
    q(x) = -\frac{\gamma(x)}{\alpha(x)},
\]
уравнение \eqref{eq:линейное-уравнение} можно привести к нормальному виду
\begin{equation}
    \label{eq:нормальное-линейное-уравнение}
    y' + p(x)y = q(x),
\end{equation}
где функции \(p(x)\) и \(q(x)\) определены и непрерывны в интервале \(x \in (a, b)\).

Если \(q(x) \equiv 0\), то линейное уравнение \eqref{eq:нормальное-линейное-уравнение} называется \textbf{однородным}, в противном случае -- \textbf{неоднородным}.

\section{Однородные уравнения}

Функция \(F(x, y)\) называется \textbf{однородной степени \(k\)}, если
\[
    \forall \lambda > 0 \implies F(\lambda x, \lambda y) = \lambda^k F(x, y).
\]
Примером однородной функции может служить любая форма (однородный многочлен) степени \(k\).

Следующие функции являются однородными функциями степени \(0\), \(1\), \(2\) и \(k\) соответственно:
\[
    \frac{x - y}{x + y};
    \quad
    \frac{x^2 + xy}{x - y};
    \quad
    x^2 + y^2 - xy;
    \quad
    x^{k - 1}y + y^k.
\]

Дифференциальное уравнение \(\dfrac{dy}{dx} = f(x, y)\) называется \textbf{однородным}, если \(f(x, y)\) -- однородная функция степени ноль.

Уравнение \(M(x, y)dx + N(x, y)dy = 0\) является однородным, если \(M(x, y)\) и \(N(x, y)\) -- однородные функции одной и той же степени. Замена \(y = zx\) приводит однородное уравнение к уравнению с разделяющимися переменными.

\section{Линейные уравнения первого порядка}

Уравнение вида
\[
    y' + p(x)y = q(x),
\]
где \(p(x)\), \(q(x)\) -- функции, непрерывные на \([a, b]\), называется \textbf{линейным дифференциальным уравнением первого порядка}. Его решение ищут в виде
\[
    y(x) = u(x) \cdot v(x),
\]
где \(u(x)\), \(v(x)\) -- две неизвестные функции. После подстановки в уравнение выражений для \(y\) и \(y'\) получаем
\[
    v \frac{du}{dx} + \Big( \frac{dv}{dx} + p(x)v \Big) u = q(x).
\]
В качестве \(v(x)\) выбирают одну из функций, удовлетворяющих уравнению
\[
    \frac{dv}{dx} + p(x)v = 0.
\]
Тогда функция \(u(x)\) определяется из уравнения
\[
    v \frac{du}{dx} = q(x).
\]

\section{Уравнение Бернулли}

Уравнение вида
\[
    y' + p(x)y = q(x)y^\alpha,
\]
где \(\alpha \in R (\alpha \neq 0, \alpha \neq 1)\), называется \textbf{уравнением Бернулли}. Путем подстановки \(z = y^{1 - \alpha}\) оно сводится к линейному. Его можно решать и непосредственно, применяя подстановку
\[
    y(x) = u(x) \cdot v(x).
\]

\section{Уравнение в полных дифференциалах}

\subsection{Определение}

Уравнение вида
\[
    M(x, y) dx + N(x, y)dy = 0
\]
называется \textbf{уравнением в полных дифференциалах}, если его левая часть есть полный дифференциал некоторой функции \(u(x, y)\). В этом случае уравнение можно записать в виде \(du(x, y) = 0\), откуда следует, что соотношение \(u(x, y) = C\) является его общим интегралом.

Выражение
\[
    M(x, y)dx + N(x, y)dy,
\]
где \(M\), \(N\) -- непрерывные функции вместе со своими частными производными \(\dfrac{\partial M}{\partial y}\) и \(\dfrac{\partial N}{\partial x}\) в некоторой области \(D\), есть \textbf{полный дифференциал} тогда и только тогда, когда \(\dfrac{\partial M}{\partial y} = \dfrac{\partial N}{\partial x}\) во всей области \(D\).

\subsection{Решение уравнений}

Рассмотрим пример. Пусть необходимо решить следующее уравнение:
\[
    (3x^2 + 6xy^2) dx + (6x^2y + 4y^3) dy = 0.
\]

Пусть
\[
    M(x, y) = 3x^2 + 6xy^2,
    \qquad
    N(x, y) = 6x^2y + 4y^3.
\]

Так как
\[
    \frac{\partial M}{\partial y} = 12xy,
    \quad
    \frac{\partial N}{\partial x} = 12xy,
    \quad
    \frac{\partial M}{\partial y} = \frac{\partial N}{\partial x},
\]
то данное уравнение является уравнением в полных дифференциалах. Значит
\[
    Mdx + Ndy = du.
\]
Следовательно
\[
    Mdx + Ndy = \frac{\partial u}{\partial x} dx + \frac{\partial u}{\partial y}dy
    \implies
    \frac{\partial u}{\partial x} = M,
    \quad
    \frac{\partial u}{\partial y} = N.
\]
\[
    \begin{dcases}
        \frac{\partial u}{\partial x} = 3x^2 + 6xy^2, \\
        \frac{\partial u}{\partial y} = 6x^2y + 4y^3.
    \end{dcases}
\]

Проинтегрируем первое уравнение по \(x\), считая \(y\) постоянной:
\[
    u(x, y) =
    \int (3x^2 + 6xy^2)dx =
    3 \cdot \frac{x^3}{3} + 6y^2 * \frac{x^2}{2} + \varphi(y) =
    x^3 + 3x^2y^2 + \varphi(y),
\]
где \(\varphi(y)\) -- произвольная непрерывно-дифференцируемая функция. Для полученной функции \(u(x, y)\) найдем частную производную по \(y\):
\[
    \frac{\partial u}{\partial y} = 6x^2y + \varphi'(y).
\]
Объединим это уравнение и второе уравнение системы:
\begin{gather*}
    6x^2y + \varphi'(y) = 6x^2y + 4y^3 \\
    \varphi'(y) = 4y^3 \\
    \varphi(y) = y^4 + C.
\end{gather*}

Подставим \(\varphi(y)\) в ранее найденную функцию \(u(x, y)\):
\[
    u(x, y) = x^3 + 3x^2y^2 + y^4 + C.
\]

Общий интеграл дифференциального уравнения:
\[
    x^3 + 3x^2y^2 + y^4 = C.
\]

\section{Дифференциальные уравнения высших порядков, допускающие понижение порядка}

\subsection{Определение}

Общий вид дифференциальных уравнений высшего порядка:
\[
    F \Big( x, y, y', y'', \ldots, y^{(n)} \Big) = 0.
\]
Допускают понижение порядка следующие типы дифференциальных уравнений:
\begin{enumerate}
    \item Уравнение вида \(y^{(n)} = f(x)\) решается путем \(n\)-кратного интегрирования.
    \item Уравнение вида \(F(x, y', y'') = 0\), явно \textbf{не содержащее искомой функции} \(y(x)\), сводят к уравнению первого порядка путем введения новой неизвестной функции \(z = z(x)\). Полагая \(y'(x) = z(x)\), \(y''(x) = z'(x)\), уравнение принимает вид \(F(x, z, z') = 0\).
    \item Уравнение вида \(F(y, y', y'') = 0\) явно \textbf{не содержащее независимой переменной} \(x\), интегрируют с помощью подстановки \(p = y'\), где \(p = p(y)\) -- новая не известная функция, зависящая от \(y\). Тогда \(y'' = p \cdot p'\). При этом порядок уравнение понижается на единицу.
    \item Если левая часть дифференциального уравнения \textbf{есть точная производная} какой-либо функции, то порядок уравнения так же можно понизить.
\end{enumerate}

\subsection{Примеры точных производных}

\begin{gather*}
    \frac{y'}{y} = (\ln y)';
    \qquad
    \frac{y''}{y'} = (\ln y')';
    \\
    xy'' + y' = (xy')';
    \qquad
    yy'' + (y')^2 = (yy')';
    \\
    \frac{yy'' - (y')^2}{y^2} = \Big( \frac{y'}{y} \Big)'.
\end{gather*}

\section{Линейные однородные дифференциальные уравнения с постоянными коэффициентами}

Чтобы решить ЛОДУ с постоянными коэффициентами
\begin{equation}
    \label{eq:lhde}
    a_0 y^{(n)} + a_1 y^{(n - 1)} + \ldots + a_{n - 1} y' + a_n y = 0,
\end{equation}
надо составить характеристическое уравнение
\begin{equation}
    \label{eq:lhde-characteristic}
    a_0 \lambda^n + a_1 \lambda^{n - 1} + \ldots + a_{n - 1} \lambda + a_n = 0
\end{equation}
и найти все его корни \(\lambda_1, \ldots, \lambda_n\).

Общее решение уравнения \eqref{eq:lhde} есть сумма, состоящая из слагаемых вида \(C_i e^{\lambda_i x}\) для каждого простого корня \(\lambda_i\) уравнения \eqref{eq:lhde-characteristic} и слагаемых вида
\begin{equation}
    \label{eq:lhde-general}
    \big( C_{m + 1} + C_{m + 2}x + C_{m + 3}x^2 + \ldots + C_{m + k} x^{k - 1} \big) e^{\lambda x}
\end{equation}
для каждого кратного корня \(\lambda\) уравнения \eqref{eq:lhde-characteristic}, где \(k\) -- кратность корня. Все \(C_i\) -- произвольные постоянные.

Для каждой пары комплексных сопряженных корней \(\lambda = \alpha \pm i \beta\) в формулу общего решения включаются слагаемые
\[
    C_{m + 1} e^{\alpha x} \cos \beta x + C_{m + 2} e^{\alpha x} \sin \beta x,
\]
если эти корни простые, и слагаемые
\[
    P_{k - 1}(x) e^{\alpha x} \cos{\beta x} + Q_{k - 1}(x) e^{\alpha x} \sin{\beta x},
\]
если каждый из корней \(\alpha + i \beta\) и \(\alpha - i \beta\) имеет кратность \(k\). Здесь \(P_{k - 1}\) и \(Q_{k - 1}\) -- многочлены степени \(k - 1\), аналогичные многочлену в \eqref{eq:lhde-general}, их коэффициенты -- произвольные постоянные.

Например, вид общего решения уравнения второго порядка
\[
    y'' + a_1 y' + a_2 y = 0
\]
с постоянными коэффициентами зависит от корней характеристического уравнения
\[
    \lambda^2 + a_1 \lambda + a_2 = 0.
\]

Если \(\lambda_1\) и \(\lambda_2\) -- различные и действительные корни, общее решение имеет вид
\[
    y = C_1 e^{\lambda_1 x} + C_2 e^{\lambda_2 x}.
\]

Если \(\lambda_1 = \lambda_2 = \lambda\) -- двукратный действительный корень, общее решение имеет вид
\[
    y = C_1 e^{\lambda x} + C_2 x e^{\lambda x}.
\]

Если \(\lambda_{1, 2} = \alpha \pm i \beta\) -- комплексно-сопряженные корни, общее решение имеет вид
\[
    y = e^{\alpha x} (C_1 \cos \beta x + C_2 \sin \beta x).
\]

\section{Линейные неоднородные дифференциальные уравнения с постоянными коэффициентами}

Рассмотрим уравнение
\[
    y^{(n)} + p_1 y^{(n - 1)} + \ldots + p_n y = f(x).
\]
Общее решение этого уравнения равно сумме какого-нибудь частного решения этого уравнения и общего решения соответствующего однородного уравнения, то есть
\[
    y(x) = y_0(x) + \bar{y}(x).
\]

Решение однородного уравнения определяется также, как было описано ранее. Частное решение уравнения \(\bar{y}(x)\) в случае, когда правая часть имеет специальный вид, определяется методом неопределенных коэффициентов. Правая часть специального вида
\[
    f(x) = e^{\alpha x} (P_m(x) \cos \beta x + Q_n(x) \sin \beta x),
\]
где \(P_m(x)\) и \(Q_n(x)\) -- полиномы степеней \(m\) и \(n\) соответственно. Укажем вид частного решения дифференциального уравнения в двух случаях.

Первый случай: число \(\alpha + i \beta\) не является корнем характеристического уравнения:
\[
    \bar{y}(x) = e^{\alpha x} (S_l(x) \cos \beta x + R_l(x) \sin \beta x),
\]
где \(S_l\) и \(R_l\) -- полиномы степени \(l = \max(m, n)\) с неопределенными коэффициентами.

Второй случай: число \(\alpha + i \beta\) является корнем характеристического уравнения кратности \(k\):
\[
    \bar{y}(x) = x^k e^{\alpha x} (S_l(x) \cos \beta x + R_l(x) \sin \beta x),
\]
то есть частное решение приобретает множитель \(x^k\).

\section{Метод Лагранжа}

Общее решение \(y(x)\) линейного неоднородного уравнения второго порядка
\[
    y'' + p_1(x)y' + p_2(x)y = f(x)
\]
есть сумма общего решения \(y_0\) соответствующего ему однородного уравнения \(y'' + p_1(x)y' + p_2(x)y = 0\) и какого-нибудь частного решения \(\bar{y}\):
\[
    y(x) = y_0(x) + \bar{y}.
\]
Суть метода Лагранжа вариации произвольных постоянных заключается в следующем. Если \(y_0 = C_1 y_1 + C_2 y_2\) -- общее решение однородного уравнения, то частное решение \(\bar{y}(x)\) ищется в виде
\[
    \bar{y} = C_1(x) y_1 + C_2(x) y_2,
\]
где \(C_1(x)\) и \(C_2(x)\) -- неизвестные пока функции, производные от которых определяются из системы
\[
    \begin{dcases}
        C_1'(x) y_1 + C_2'(x)y_2 = 0
        C_1'(x) y_1' + C_2'(x)y_2' = f(x).
    \end{dcases}
\]
Решая данную систему, находим \(C_1'(x)\) и \(C_2'(x)\), откуда после интегрирования определяем \(C_1(x)\) и \(C_2(x)\).

\chapter{Числовые ряды}

\section{Основные понятия}

\begin{definition*}
    Выражение вида
    \[
        \sum_{n = 1}^{\infty} a_n = a_1 + a_2 + \ldots + a_n + \ldots,
    \]
    называют \textbf{числовым рядом}. Числа \(a_1, a_2, \ldots, a_n, \ldots\) -- действительные или комплексные числа, называющиеся членами ряда, а \(a_n\) -- \(n\)-ый или общий член ряда.
\end{definition*}

Ряд задан, если известен общий член ряда \(a_n\), выраженных как функция его номера \(n\): \(a_n = f(n)\).

Сумму первых \(n\) членов числового ряда обозначают через \(S_n\) и называют \(n\)-й частичной суммой ряда:
\[
    S_n = a_1 + a_2 + \ldots + a_n.
\]

Ряд вида
\[
    \sum_{k = n + 1}^{\infty} a_k = a_{n + 1} + a_{n + 2} + \ldots
\]
называется \(n\)-м остатком ряда \(\displaystyle \sum_{n = 1}^{\infty} a_n\), который получается отбрасыванием его \(n\) первых членов.

Ряд называется \textbf{сходящимся}, если его \(n\)-я частичная сумма \(S_n\) при неограниченном возрастании \(n\) стремится к конечному пределу, т. е. если
\[
    \lim_{n \to \infty} = S.
\]
Число \(S\) называют \textbf{суммой} ряда. Если же \(n\)-я частичная сумма ряда не стремиться к конечному пределу, то ряд называют \textbf{расходящимся}.

\section{Свойства числовых рядов}
\label{sec:num-series-props}

\begin{property}
    Если ряд
    \begin{equation}
        \label{eq:series-prop-1}
        \sum_{n = 1}^{\infty} a_n = a_1 + a_2 + \ldots + a_n + \ldots
    \end{equation}
    сходится и его сумма равна \(S\), то ряд
    \begin{equation}
        \label{eq:series-with-constant-prop-1}
        \sum_{n = 1}^{\infty} \lambda a_n = \lambda a_1 + \lambda a_2 + \ldots + \lambda a_n + \ldots,
    \end{equation}
    где \(\lambda\) -- произвольное число, также сходится и его сумма равна \(\lambda S\). Если же ряд \eqref{eq:series-prop-1} расходится и \(\lambda \neq 0\), то и ряд \eqref{eq:series-with-constant-prop-1} расходится.

    \begin{proof}
        \newpar
        \textbf{Сходимость}. Пусть \(S_n\) -- \(n\)-я частичная сумма ряда \eqref{eq:series-with-constant-prop-1}. Тогда
        \[
            S_n^{(a)} = \lambda a_1 + \lambda a_2 + \ldots + \lambda a_n + \ldots =
            \lambda (a_1 + a_2 + \ldots + a_n + \ldots) =
            \lambda S_n.
        \]
        \[
            \lim_{n \to \infty} S_n^{(a)} =
            \lim_{n \to \infty} \lambda S_n =
            \lambda \lim_{n \to \infty} S_n =
            \lambda S.
        \]

        Так как существует конечный предел частичных сумм, то ряд \eqref{eq:series-with-constant-prop-1} сходится и имеет сумму \(\lambda S\).

        \textbf{Расходимость}. Допустим противное. Пусть ряд \eqref{eq:series-with-constant-prop-1} сходится и имеет сумму \(S_1\). Тогда
        \[
            S_1 = \lim_{n \to \infty} S_n^{(a)} =
            \lim_{n \to \infty} \lambda S_n =
            \lambda \lim_{n \to \infty} S_n
            \implies
            \lim_{n \to \infty} S_n = \frac{S_1}{\lambda}.
        \]
        т. е. ряд \eqref{eq:series-prop-1} сходится, что противоречит условию о расходимости данного ряда.
    \end{proof}
\end{property}

\begin{property}
    Если сходится ряд
    \begin{equation}
        \label{eq:series-a-prop-2}
        \sum_{n = 1}^{\infty} a_n = a_1 + a_2 + \ldots + a_n + \ldots
    \end{equation}
    и сходится ряд
    \begin{equation}
        \label{eq:series-b-prop-2}
        \sum_{n = 1}^{\infty} b_n = b_1 + b_2 + \ldots + b_n + \ldots,
    \end{equation}
    а их суммы равны \(S_a\) и \(S_b\) соответственно, то сходятся и ряды
    \begin{equation}
        \label{eq:series-ab-prop-2}
        \sum_{n = 1}^{\infty} (a_n \pm b_n),
    \end{equation}
    причем сумма каждого равна \(S_a \pm S_b\).

    \begin{proof}
        Пусть \(S_n^{(a)}\), \(S_n^{(b)}\), \(S_n\) -- \(n\)-е частичные суммы рядов \eqref{eq:series-a-prop-2}, \eqref{eq:series-b-prop-2} и \eqref{eq:series-ab-prop-2} соответственно. Тогда
        \[
            \lim_{n \to \infty} S_n =
            \lim_{n \to \infty} (S_n^{(a)} \pm S_n^{(b)}) =
            \lim_{n \to \infty} S_n^{(a)} \pm \lim_{n \to \infty} S_n^{(b)} =
            S_a \pm S_b,
        \]
        т. е. каждый из рядов \eqref{eq:series-ab-prop-2} сходится и его сумма равна \(S_a \pm S_b\).
    \end{proof}

    \begin{consequence*}
        Сумма (разность) сходящегося и расходящегося рядов есть расходящийся ряд.
    \end{consequence*}

    \begin{note*}
        Сумма (разность) двух расходящимся рядов может быть как сходящимся, так и расходящимся рядом.
    \end{note*}
\end{property}

\begin{property}
    Если к ряду
    \begin{equation}
        \label{eq:series-prop-3}
        \sum_{n = 1}^{\infty} a_n = a_1 + a_2 + \ldots + a_n + \ldots
    \end{equation}
    прибавить (или отбросить) конечное число членов, то полученный ряд и ряд \eqref{eq:series-prop-3} сходятся или расходятся одновременно.

    \begin{proof}
        Пусть \(S\) -- сумма отброшенных членов ряда, а \(k\) -- наибольший из этих номеров. Будем считать, что на место отброшенных членов ряда поставили нули. Тогда при \(n > k\) выполняется равенство
        \[
            S_n - S_n' = S,
        \]
        где \(S_n'\) -- \(n\)-я частичная сумма ряда, полученная из ряда \eqref{eq:series-prop-3} путем отбрасывания конечного числа членов. Поэтому
        \[
            \lim_{n \to \infty} S_n = S + \lim_{n \to \infty} S_n'.
        \]

        Пределы в левой и правой части данного равенства одновременно существуют или не существуют, т. е. ряд \eqref{eq:series-prop-3} сходится (расходится) тогда и только тогда, когда сходятся (расходятся) ряды без конечного числа его членов.

        Аналогично доказывается случай приписывания к ряду конечного числа членов.
    \end{proof}
    \begin{consequence}
        Ряд \eqref{eq:series-prop-3} и его \(n\)-й остаток сходятся или расходятся одновременной.
    \end{consequence}
    \begin{consequence}
        Если ряд \eqref{eq:series-prop-3} сходится, то его \(n\)-й остаток \(r_n\) стремится к нулю при \(n \to \infty\), т. е.
        \[
            \lim_{n \to \infty} r_n = 0.
        \]
    \end{consequence}
\end{property}

\section{Ряд геометрической прогрессии}

\begin{definition*}
    Ряд вида
    \[
        a + aq + aq^2 + \ldots + aq^{n - 1} + \ldots,
        \quad
        (a \neq 0)
    \]
    называется \textbf{рядом геометрической прогрессии}.
\end{definition*}

Исследуем данный ряд на сходимость. Сумма первых \(n\) членов прогрессии находится по формуле
\[
    S_n = \frac{a (1 - q^n)}{1 - q},
    \quad
    q \neq 1.
\]

Найдем предел этой суммы:
\[
    \lim_{n \to \infty} S_n =
    \lim_{n \to \infty} \frac{a (1 - q^n)}{1 - q} =
    \frac{a}{1 - q} - a \lim_{n \to \infty} \frac{q^n}{1 - q}.
\]

Рассмотрим следующие случаи:
\begin{enumerate}
    \item Если \(|q| < 1\), то \(q^n \to 0\) при \(n \to \infty\), значит \(\displaystyle \lim_{n \to \infty} S_n = \frac{a}{1 - q}\), т. е. ряд сходится и его сумма равна \(\dfrac{a}{1 - q}\).
    \item Если \(|q| > 1\), то \(q^n \to \infty\) при \(n \to \infty\), значит \(\displaystyle \lim_{n \to \infty} S_n = \infty\), т. е. ряд расходится.
    \item Если \(q = 1\), получаем ряд \(a + a + a + \ldots\), который расходится, так как \(S_n = na\), значит \(\displaystyle \lim_{n \to \infty} S_n = \infty\).
    \item Если \(q = -1\), получаем ряд \(a - a + a - a + \ldots\), который расходится, так как \(\displaystyle \lim_{n \to \infty} S\) не существует.
\end{enumerate}

Таким образом, ряд геометрической прогрессии сходится при \(|q| < 1\) и расходится при \(|q| \geq 1\).

\section{Гармонический ряд}

\begin{definition*}
    Ряд вида
    \[
        \sum_{n = 1}^{\infty} \frac{1}{n} = 1 + \frac{1}{2} + \frac{1}{3} + \ldots + \frac{1}{n} + \ldots
    \]
    называется \textbf{гармоническим рядом}. У данного ряда каждый член является средним гармоническим для двух соседних членов.
\end{definition*}

\begin{definition}
    Гармоническое среднее чисел \(x_1, x_2, \ldots, x_n\) -- это такое число \(h\), обратное которому есть среднее арифметическое чисел, обратных данным числам:
    \[
        h = \frac{n}{\dfrac{1}{x_1} + \dfrac{1}{x_2} + \ldots + \dfrac{1}{x_n}}.
    \]
\end{definition}

\section{Необходимый признак сходимости}

\begin{theorem*}
    Если ряд сходится, то его общий член \(a_n\) стремится к нулю при \(n \to \infty\), то есть
    \[
        \lim_{n \to \infty} a_n = 0.
    \]

    \begin{proof}
        Пусть дан сходящийся ряд
        \[
            \sum_{n = 1}^{\infty} a_n = a_1 + a_2 + \ldots + a_n + \ldots,
        \]
        причем \(\displaystyle \lim_{n \to \infty} S_n = S\). Тогда \(\displaystyle \lim_{n \to \infty} S_{n - 1} = S\) при \(n \to \infty\) и \((n - 1) \to \infty\). Учитывая, что \(a_n = S_n - S_{n - 1}\) при \(n > 1\), получим
        \[
            \lim_{n \to \infty} a_n =
            \lim_{n \to \infty} (S_n - S_{n - 1}) =
            \lim_{n \to \infty} S_n - \lim_{n \to \infty} S_{n - 1} =
            S - S = 0.
        \]
    \end{proof}

    \begin{consequence*}[достаточное условие расходимости ряда]
        \newpar
        Если \(\displaystyle \lim_{n \to \infty} a_n \neq 0\) или не существует, то ряд расходится.
    \end{consequence*}
\end{theorem*}

\section{Признаки сравнения}

\begin{theorem}
    \label{thm:series-comparing-1}
    Пусть даны два знакоположительных ряда \(\displaystyle \sum_{n = 1}^{\infty} a_n\) и \(\displaystyle \sum_{n = 1}^{\infty} b_n\). Если для всех \(n\) выполняется неравенство \(a_n \leq b_n\), то эти ряды сходятся или расходятся одновременно.

    \begin{proof}
        Пусть \(S_n^{(a)}\) и \(S_n^{(b)}\) -- \(n\)-e частичные суммы этих рядов. Так как \(\forall n \implies a_n \leq b_n\):
        \[
            S_n^{(a)} \leq S_n^{(b)}.
        \]

        Докажем, что если сходится ряд \(\displaystyle \sum_{n = 1}^{\infty} b_n\), то сходится и ряд \(\displaystyle \sum_{n = 1}^{\infty} a_n\). Пусть ряд \(\displaystyle \sum_{n = 1}^{\infty} b_n\) сходится и его сумма равна \(S_b\). Тогда
        \[
            \lim_{n \to \infty} S_n^{(b)} = S_b.
        \]

        Члены этого ряда положительны, поэтому
        \[
            S_n^{(b)} < S_b.
        \]

        Так как \(\forall n \implies a_n \leq b_n\), имеем
        \[
            S_n^{(a)} < S_b.
        \]

        Таким образом, последовательность \(S_1^{(a)}, S_2^{(a)}, \ldots, S_n^{(a)}\) монотонно возрастает и ограничена сверху числом \(S_n\). По признаку существования предела последовательности последовательность \(\{S_n^{(a)}\}\) имеет предел \(\displaystyle \lim_{n \to \infty} S_n^{(a)} = S_a\), т.е. ряд сходится.

        Пусть теперь ряд \(\displaystyle \sum_{n = 1}^{\infty} a_n\) расходится. Так как члены неотрицательны, то
        \[
            \lim_{n \to \infty} S_n^{(a)} = \infty.
        \]

        Так как \(\forall n \implies a_n \leq b_n\), имеем
        \[
            \lim_{n \to \infty} S_n^{(b)} = \infty,
        \]
        то есть ряд \(\displaystyle \sum_{n = 1}^{\infty} b_n\) расходится.
    \end{proof}

    \begin{note*}
        Теорема справедлива и в том случае, когда неравенство \(a_n \leq b_n\) выполняется не для всех членов рядов, а начиная с некоторого номера.
    \end{note*}
\end{theorem}

\begin{theorem}[предельный признак сравнения]
    Пусть даны два знакоположительных ряда \(\displaystyle \sum_{n = 1}^{\infty} a_n\) и \(\displaystyle \sum_{n = 1}^{\infty} b_n\). Если существует конечный, отличный от нуля предел
    \[
        \lim_{n \to \infty} \frac{a_n}{b_n} = A
        \quad
        (0 < A < \infty),
    \]
    то эти ряды сходятся или расходятся одновременно.

    \begin{proof}
        По определению предела последовательности для всех \(n\), кроме, возможно, их конечного числа, для любого \(\varepsilon > 0\)
        \[
            \Big| \frac{a_n}{b_n} - A \Big| < \varepsilon,
        \]
        \[
            (A - \varepsilon) b_n < a_n < (A + \varepsilon) b_n.
        \]

        Если ряд \(\displaystyle \sum_{n = 1}^{\infty} a_n\) сходится, то из неравенства \((A - \varepsilon) b_n < a_n\) и \hyperref[thm:series-comparing-1]{предыдущей теоремы} следует, что ряд \(\displaystyle \sum_{n = 1}^{\infty} (A - \varepsilon) b_n\) также сходится. Тогда, согласной \hyperref[sec:num-series-props]{свойству числовых рядов}, ряд \(\displaystyle \sum_{n = 1}^{\infty} b_n\) также сходится.

        Если ряд \(\displaystyle \sum_{n = 1}^{\infty} a_n\) расходится, то из неравенства \(a_n < (A + \varepsilon) b_n\), \hyperref[thm:series-comparing-1]{предыдущей теоремы} и \hyperref[sec:num-series-props]{свойства числовых рядов} ряд \(\displaystyle \sum_{n = 1}^{\infty} b_n\) также расходится.

        Аналогично, если ряд \(\displaystyle \sum_{n = 1}^{\infty} b_n\) сходится (расходится), то будет сходиться (расходиться) и ряд \(\displaystyle \sum_{n = 1}^{\infty} a_n\).
    \end{proof}
\end{theorem}

\end{document}
